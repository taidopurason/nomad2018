{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this notebook requires lightgbm and mlxtend to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing functions\n",
    "%run helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior transformation of data\n",
    "* Adding calculated values (calculated in Data preparation.ipynb)\n",
    "* Engineering new features from spacegroup\n",
    "* Filling missing values\n",
    "* Applying log-transformation to some features *(\"cAlGa\", \"cAlIn\", \"cGaAl\", \"cInAl\", \"cInGa\", \"distAlO\", \"distGaAl\", \"distGaIn\", \"distGaO\", \"distInAl\", \"distInGa\", \"distInO\", \"spacegroup\")*\n",
    "* Standardizing\n",
    "\n",
    "These are done in helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formation energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.03063770639495525\n",
      "CV score with log-transformation on target: 0.03067388533613983\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "params_fe = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.07,\n",
    "    \"n_estimators\":90,\n",
    "    \"num_leaves\": 15}\n",
    "lgbm_fe = LGBMRegressor(**params_fe)\n",
    "print(\"CV score:\", evaluate_CV(lgbm_fe, X_full, y_fe))\n",
    "print(\"CV score with log-transformation on target:\",evaluate_CV(lgbm_fe, X_full, np.log1p(y_fe), metric=rmsle_scorer_exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bandgap energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.08652825493907336\n",
      "CV score with log-transformation on target: 0.08626319311731868\n"
     ]
    }
   ],
   "source": [
    "params_be = {\"boosting_type\": \"gbdt\",\n",
    "         \"max_depth\": 5,\n",
    "         \"learning_rate\": 0.12,\n",
    "         \"n_estimators\":100,\n",
    "         \"num_leaves\": 20}\n",
    "lgbm_be = LGBMRegressor(**params_be)\n",
    "print(\"CV score:\", evaluate_CV(lgbm_be, X_full, y_be))\n",
    "print(\"CV score with log-transformation on target:\", evaluate_CV(lgbm_be, X_full, np.log1p(y_be), metric=rmsle_scorer_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for submitting to Kaggle\n",
    "#lgbm_be.fit(X_full, np.log1p(y_be))\n",
    "#lgbm_fe.fit(X_full, np.log1p(y_fe))\n",
    "#save_results(np.expm1(lgbm_fe.predict(X_full_test)), np.expm1(lgbm_be.predict(X_full_test)), \"baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline kaggle private score: 0.06645"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will test if using PCA will give any benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "cols =['lattice_vector_1_ang', 'lattice_vector_2_ang', 'lattice_vector_3_ang']\n",
    "pca.fit(X_full[cols])\n",
    "X_full[\"pca_lattice_vector\"] = pca.transform(X_full[cols])\n",
    "pca.fit(X_full_test[cols])\n",
    "X_full_test[\"pca_lattice_vector\"] = pca.transform(X_full_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1)\n",
    "cols=['lattice_angle_alpha_degree', 'lattice_angle_beta_degree', 'lattice_angle_gamma_degree']\n",
    "pca.fit(X_full[cols])\n",
    "X_full[\"pca_lattice_angle\"] = pca.transform(X_full[cols])\n",
    "X_full_test[\"pca_lattice_angle\"] = pca.transform(X_full_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1)\n",
    "cols=['distAlGa','distAlIn', 'distAlO', 'distGaAl', 'distGaIn', 'distGaO', 'distInAl','distInGa', 'distInO']\n",
    "pca.fit(X_full[cols])\n",
    "X_full[\"pca_c_el\"] = pca.transform(X_full[cols])\n",
    "X_full_test[\"pca_c_el\"] = pca.transform(X_full_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.030211969787901728\n",
      "CV score with log-transformation on target: 0.030485969276569446\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "params_fe = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.07,\n",
    "    \"n_estimators\":90,\n",
    "    \"num_leaves\": 15}\n",
    "lgbm_fe = LGBMRegressor(**params_fe)\n",
    "print(\"CV score:\",evaluate_CV(lgbm_fe, X_full, y_fe))\n",
    "print(\"CV score with log-transformation on target:\", evaluate_CV(lgbm_fe, X_full, np.log1p(y_fe), metric=rmsle_scorer_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.08639266895047162\n",
      "CV score with log-transformation on target: 0.08552706058401505\n"
     ]
    }
   ],
   "source": [
    "params_be = {\"boosting_type\": \"gbdt\",\n",
    "         \"max_depth\": 5,\n",
    "         \"learning_rate\": 0.12,\n",
    "         \"n_estimators\":100,\n",
    "         \"num_leaves\": 20}\n",
    "lgbm_be = LGBMRegressor(**params_be)\n",
    "print(\"CV score:\",evaluate_CV(lgbm_be, X_full, y_be))\n",
    "print(\"CV score with log-transformation on target:\",evaluate_CV(lgbm_be, X_full, np.log1p(y_be), metric=rmsle_scorer_exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing if dropping any columns will give a better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: 0.08639266895047162\n",
      "number_of_total_atoms 0.08602563750126518\n",
      "percent_atom_al 0.08575569154662085\n",
      "percent_atom_in 0.0863257818025154\n",
      "lattice_vector_1_ang 0.08562369197922594\n",
      "lattice_vector_2_ang 0.08558426456169058\n",
      "lattice_vector_3_ang 0.08633343297594909\n",
      "lattice_angle_alpha_degree 0.08604188785988934\n",
      "cAlAl 0.08502142098864722\n",
      "cAlGa 0.08579877209913324\n",
      "cAlIn 0.08604349355260768\n",
      "cAlO 0.08637511851915505\n",
      "cGaAl 0.0857408966282995\n",
      "cGaIn 0.08557128223396028\n",
      "cGaO 0.08625754044373726\n",
      "cInIn 0.08541019321765204\n",
      "cInO 0.0863532990038598\n",
      "distAlAl 0.08551791559975859\n",
      "distGaGa 0.08616658448915483\n",
      "distInIn 0.08600330002563036\n",
      "qAl 0.08625762457633203\n",
      "qGa 0.08563125125815801\n",
      "qO 0.08585620289255688\n",
      "xEq 0.0860439295173042\n",
      "centroSym 0.08630882342844616\n",
      "pca_lattice_vector 0.08601167378886712\n",
      "pca_c_el 0.08583396003602237\n"
     ]
    }
   ],
   "source": [
    "lgbm_be = LGBMRegressor(**params_be)\n",
    "baseline = evaluate_CV(lgbm_be, X_full, y_be) \n",
    "print(\"baseline:\", baseline)\n",
    "for col in X_full.columns:\n",
    "    new_score = evaluate_CV(lgbm_be, X_full.drop(col,axis=1), y_be)\n",
    "    if baseline > new_score:\n",
    "        print(col, new_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08614692938856561\n",
      "0.08534471191544954\n"
     ]
    }
   ],
   "source": [
    "lgbm_be = LGBMRegressor(**params_be)\n",
    "cols_to_drop = [\"pca_lattice_vector\", \"cAlIn\"]\n",
    "print(evaluate_CV(lgbm_be, X_full.drop(cols_to_drop, axis=1), y_be))\n",
    "print(evaluate_CV(lgbm_be, X_full.drop(cols_to_drop, axis=1), np.log1p(y_be), metric=rmsle_scorer_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: 0.030211969787901728\n",
      "percent_atom_al 0.0302072306701917\n",
      "lattice_angle_beta_degree 0.030164963888679654\n",
      "lattice_angle_gamma_degree 0.030190009568097163\n",
      "Vatom 0.030004156245694392\n",
      "cAlIn 0.030174836091060496\n",
      "cGaGa 0.030201113709556006\n",
      "cGaIn 0.030177571343190705\n",
      "cInAl 0.030016644020729278\n",
      "distGaGa 0.03018846289205309\n"
     ]
    }
   ],
   "source": [
    "lgbm_fe = LGBMRegressor(**params_fe)\n",
    "baseline = evaluate_CV(lgbm_fe, X_full, y_fe) \n",
    "print(\"baseline:\", baseline)\n",
    "for col in X_full.columns:\n",
    "    new_score = evaluate_CV(lgbm_fe, X_full.drop(col,axis=1), y_fe)\n",
    "    if baseline > new_score:\n",
    "        print(col, new_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029818649156244985\n",
      "0.029756252049120663\n"
     ]
    }
   ],
   "source": [
    "lgbm_fe = LGBMRegressor(**params_fe)\n",
    "cols_to_drop = [\"cAlIn\", \"cInAl\"]\n",
    "print(evaluate_CV(lgbm_fe, X_full.drop(cols_to_drop, axis=1), y_fe))\n",
    "print(evaluate_CV(lgbm_fe, X_full.drop(cols_to_drop, axis=1), np.log1p(y_fe), metric=rmsle_scorer_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_be = X_full.drop([\"cAlIn\"], axis=1)\n",
    "X_full_fe = X_full.drop([\"cAlIn\", \"cInAl\"], axis=1)\n",
    "X_full_test_be = X_full_test.drop([\"cAlIn\"], axis=1)\n",
    "X_full_test_fe = X_full_test.drop([\"cAlIn\", \"cInAl\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results for kaggle\n",
    "#lgbm_be.fit(X_full_be, np.log1p(y_be))\n",
    "#lgbm_fe.fit(X_full_fe, np.log1p(y_fe))\n",
    "#save_results(np.expm1(lgbm_fe.predict(X_full_test_fe)), np.expm1(lgbm_be.predict(X_full_test_be)), \"removal + pca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle private score without pca: 0.06631\n",
    "\n",
    "Kaggle private score with pca: 0.06681\n",
    "\n",
    "**We can conclude that PCA didn't help us achieve better results for the test dataset. Dropping certain columns will be beneficial.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a stacked model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reloading the dataset before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset features\n",
    "%run helper_functions.ipynb\n",
    "useless_cols = ['cAlAl', 'cInIn', 'cGaGa', 'distAlAl', 'distInIn', 'distGaGa']\n",
    "X_full.drop(useless_cols, axis=1, inplace=True)\n",
    "X_full_test.drop(useless_cols, axis=1, inplace=True)\n",
    "X_full_be = X_full.drop([\"cAlIn\"], axis=1)\n",
    "X_full_fe = X_full.drop([\"cAlIn\", \"cInAl\"], axis=1)\n",
    "X_full_test_be = X_full_test.drop([\"cAlIn\"], axis=1)\n",
    "X_full_test_fe = X_full_test.drop([\"cAlIn\", \"cInAl\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning some additional models for the 2-level regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_search(model, grid, fe=True, transform_target=True):\n",
    "    gs = GridSearchCV(model, grid, n_jobs=-1, scoring=(rmsle_scorer_exp if transform_target else rmsle_scorer), cv=3)\n",
    "    target = (y_fe if fe else y_be)\n",
    "    gs.fit(X_full_fe if fe else X_full_be , np.log1p(target) if transform_target else target)\n",
    "    print(f\"best score: {gs.best_score_}\")\n",
    "    print(f\"best params: {gs.best_params_}\")\n",
    "    return gs.best_params_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: -0.09343253434423777\n",
      "best params: {'alpha': 0.0001, 'random_state': 3}\n",
      "best score: -0.04665305684703571\n",
      "best params: {'alpha': 0.0001, 'random_state': 3}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Ridge()\n",
    "grid = {\n",
    "    \"alpha\":[0.0001,0.005,0.01,0.05,0.1,0.5,1,1.5,2,2.5],\n",
    "    \"random_state\": [3]\n",
    "}\n",
    "\n",
    "ridge_params_be = param_search(model, grid, fe=False, transform_target=True)\n",
    "\n",
    "ridge_params_fe = param_search(model, grid, fe=True, transform_target=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: -0.0877859389811997\n",
      "best params: {'bootstrap': True, 'max_depth': 12, 'n_estimators': 200, 'random_state': 3}\n",
      "best score: -0.028986765224560233\n",
      "best params: {'bootstrap': True, 'max_depth': 12, 'n_estimators': 250, 'random_state': 3}\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesRegressor()\n",
    "grid = {\n",
    "    \"n_estimators\":[100,150,200,250],\n",
    "    \"max_depth\":[None,10,12,15],\n",
    "    \"bootstrap\":[True, False],\n",
    "    \"random_state\": [3]\n",
    "}\n",
    "\n",
    "et_params_be = param_search(model, grid, fe=False, transform_target=True)\n",
    "et_params_fe = param_search(model, grid, fe=True, transform_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without the added parameters\n",
    "et_params_fe={'bootstrap': True, 'max_depth': None, 'n_estimators': 250, 'random_state': 3}\n",
    "et_fe = ExtraTreesRegressor(**et_params_fe)\n",
    "params_be = {\"boosting_type\": \"gbdt\",\"max_depth\": 5,\"learning_rate\": 0.12,\"n_estimators\":100,\"num_leaves\": 20}\n",
    "lgbm_be = LGBMRegressor(**params_be)\n",
    "\n",
    "# This is for kaggle\n",
    "#lgbm_be.fit(X_full_be, np.log1p(y_be))\n",
    "#et_fe.fit(X_full_fe, np.log1p(y_fe))\n",
    "# save_results(np.expm1(et_fe.predict(X_full_test_fe)), np.expm1(lgbm_be.predict(X_full_test_be)), \"et_fe + lgbm_be\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 2-level stacking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I selected the best models from \"Parameter tuning\" and previously trained models from the other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_fe, X_val_fe, y_train_fe, y_val_fe = train_test_split(X_full_fe, y_fe, train_size=0.2, random_state=1)\n",
    "X_train_be, X_val_be, y_train_be, y_val_be = train_test_split(X_full_be, y_be, train_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline results for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fe rmsle: 0.033474786586741585\n",
      "be rmsle: 0.09690131012298847\n"
     ]
    }
   ],
   "source": [
    "params_be = {\"boosting_type\": \"gbdt\",\n",
    "         \"max_depth\": 5,\n",
    "         \"learning_rate\": 0.12,\n",
    "         \"n_estimators\":100,\n",
    "         \"num_leaves\": 20}\n",
    "lgbm_be = LGBMRegressor(**params_be)\n",
    "\n",
    "params_fe = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.07,\n",
    "    \"n_estimators\":90,\n",
    "    \"num_leaves\": 15}\n",
    "lgbm_fe = LGBMRegressor(**params_fe)\n",
    "\n",
    "lgbm_be.fit(X_train_be, np.log1p(y_train_be))\n",
    "lgbm_fe.fit(X_train_fe, np.log1p(y_train_fe))\n",
    "print(\"fe rmsle:\",rmsle(y_val_fe, np.expm1(lgbm_fe.predict(X_val_fe.values))))\n",
    "print(\"be rmsle:\",rmsle(y_val_be, np.expm1(lgbm_be.predict(X_val_be.values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formation energy models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting 1st level models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fe = RandomForestRegressor(\n",
    "    criterion='mse', \n",
    "    n_estimators=1000, \n",
    "    max_depth=35, \n",
    "    min_samples_split=4, \n",
    "    random_state=1)\n",
    "\n",
    "mlp_fe = MLPRegressor(\n",
    "    activation=\"relu\", \n",
    "    solver=\"lbfgs\", \n",
    "    learning_rate=\"invscaling\", \n",
    "    hidden_layer_sizes=(50, 50))\n",
    "\n",
    "knn_fe = KNeighborsRegressor(\n",
    "    n_neighbors=5, \n",
    "    weights='uniform', \n",
    "    metric='manhattan')\n",
    "\n",
    "params_fe = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.07,\n",
    "    \"n_estimators\":60,\n",
    "    \"num_leaves\": 15}\n",
    "\n",
    "et_params_fe={'bootstrap': True, \n",
    "              'max_depth': None, \n",
    "              'n_estimators': 250, \n",
    "              'random_state': 3}\n",
    "et_fe = ExtraTreesRegressor(**et_params_fe)\n",
    "\n",
    "\n",
    "lgbm_fe = LGBMRegressor(**params_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_fe =  [rf_fe, mlp_fe, knn_fe, lgbm_fe, et_fe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_fe = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_fe = StackingCVRegressor(regressors=clf_fe,meta_regressor=meta_fe, n_jobs=-1, random_state=3, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set score: 0.032602547281153284\n",
      "CV score: 0.029282366078403475\n"
     ]
    }
   ],
   "source": [
    "stack_fe.fit(X_train_fe.values, y_train_fe.values)\n",
    "print(\"validation set score:\",rmsle(y_val_fe, stack_fe.predict(X_val_fe.values)))\n",
    "print(\"CV score:\",evaluate_CV(stack_fe, X_full_fe.values, np.log1p(y_fe.values), metric=rmsle_scorer_exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking gives satisfactory results (higher than baseline) for FE, but it is not as good as ExtraTrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bandgap energy classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting 1st level models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_be = MLPRegressor(\n",
    "    activation=\"tanh\", \n",
    "    solver=\"lbfgs\", \n",
    "    learning_rate=\"invscaling\", \n",
    "    hidden_layer_sizes=(50, 100, 50))\n",
    "\n",
    "svr_be = SVR(kernel=\"poly\", gamma=\"scale\")\n",
    "\n",
    "params_be = {\"boosting_type\": \"gbdt\",\n",
    "         \"max_depth\": 5,\n",
    "         \"learning_rate\": 0.12,\n",
    "         \"n_estimators\":100,\n",
    "         \"num_leaves\": 20}\n",
    "\n",
    "lgbm_be = LGBMRegressor(**params_be)\n",
    "\n",
    "rf_be = RandomForestRegressor(criterion='mse', n_estimators=850, max_depth=30, min_samples_split=6, random_state=1)\n",
    "\n",
    "clf_be = [mlp_be, svr_be, lgbm_be, rf_be]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting meta-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_be = Ridge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_be = StackingCVRegressor(regressors=clf_be, meta_regressor=meta_be, random_state=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set score 0.091229740214137\n",
      "CV score: 0.0835814866889808\n"
     ]
    }
   ],
   "source": [
    "stack_be.fit(X_train_be.values, y_train_be.values)\n",
    "print(\"validation set score\", rmsle(y_val_be, stack_be.predict(X_val_be.values)))\n",
    "be_model_cv_score = evaluate_CV(stack_be, X_full_be.values, np.log1p(y_be.values), metric=rmsle_scorer_exp)\n",
    "print(\"CV score:\", be_model_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking for Bandcap energy surpasses our baseline and it will be used in the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model for formation energy prediction is ExtraTrees and for bandgap energy is the stacked model.\n",
    "\n",
    "The resulting RMSLE for formation energy: **0.0292478**\n",
    "\n",
    "The resulting RMSLE for bandcap energy: **0.0835814**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees CV error: 0.029093869184827738\n",
      "Stacked model CV error: 0.0835814866889808\n"
     ]
    }
   ],
   "source": [
    "et_params_fe={'bootstrap': True, 'max_depth': None, 'n_estimators': 250, 'random_state': 3}\n",
    "et_fe = ExtraTreesRegressor(**et_params_fe)\n",
    "\n",
    "\n",
    "print(\"ExtraTrees CV error:\", evaluate_CV(et_fe, X_full_fe.values, np.log1p(y_fe.values), metric=rmsle_scorer_exp))\n",
    "print(\"Stacked model CV error:\", be_model_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The private score in Kaggle from this model is **0.06376** (would be 61st on the [leaderboards](https://www.kaggle.com/c/nomad2018-predict-transparent-conductors/leaderboard))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formation energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>distInO</td>\n",
       "      <td>0.031358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>lattice_angle_gamma_degree</td>\n",
       "      <td>0.035526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>percent_atom_in</td>\n",
       "      <td>0.040129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>lattice_vector_2_ang</td>\n",
       "      <td>0.042988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>qIn</td>\n",
       "      <td>0.043919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>xEq</td>\n",
       "      <td>0.055097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>distAlIn</td>\n",
       "      <td>0.077329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>spacegroup</td>\n",
       "      <td>0.104610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>lattice_vector_3_ang</td>\n",
       "      <td>0.145627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>distInAl</td>\n",
       "      <td>0.147002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        column  importance\n",
       "27                     distInO    0.031358\n",
       "10  lattice_angle_gamma_degree    0.035526\n",
       "4              percent_atom_in    0.040129\n",
       "6         lattice_vector_2_ang    0.042988\n",
       "31                         qIn    0.043919\n",
       "33                         xEq    0.055097\n",
       "20                    distAlIn    0.077329\n",
       "0                   spacegroup    0.104610\n",
       "7         lattice_vector_3_ang    0.145627\n",
       "25                    distInAl    0.147002"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_fe.fit(X_full_fe, np.log1p(y_fe))\n",
    "et_fe.feature_importances_\n",
    "pd.DataFrame({\"column\":X_full_fe.columns, \"importance\":et_fe.feature_importances_}).sort_values(by=\"importance\").tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bandgap energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>cInAl</td>\n",
       "      <td>0.008762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>lattice_vector_2_ang</td>\n",
       "      <td>0.011594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>lattice_angle_gamma_degree</td>\n",
       "      <td>0.015685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>spacegroup</td>\n",
       "      <td>0.024437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>distInO</td>\n",
       "      <td>0.031036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>qIn</td>\n",
       "      <td>0.034934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>lattice_vector_3_ang</td>\n",
       "      <td>0.035538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>percent_atom_al</td>\n",
       "      <td>0.102547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>percent_atom_in</td>\n",
       "      <td>0.204406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Vatom</td>\n",
       "      <td>0.439416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        column  importance\n",
       "17                       cInAl    0.008762\n",
       "6         lattice_vector_2_ang    0.011594\n",
       "10  lattice_angle_gamma_degree    0.015685\n",
       "0                   spacegroup    0.024437\n",
       "28                     distInO    0.031036\n",
       "32                         qIn    0.034934\n",
       "7         lattice_vector_3_ang    0.035538\n",
       "2              percent_atom_al    0.102547\n",
       "4              percent_atom_in    0.204406\n",
       "11                       Vatom    0.439416"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_be = ExtraTreesRegressor(**{'bootstrap': True, 'max_depth': 12, 'n_estimators': 200, 'random_state': 3})\n",
    "et_be.fit(X_full_be, np.log1p(y_be))\n",
    "pd.DataFrame({\"column\":X_full_be.columns, \"importance\":et_be.feature_importances_}).sort_values(by=\"importance\").tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The engineered features had a significant impact on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing performance of models\n",
    "Commenting out calculation of CV scorest (takes too long). Loading precalculated results from csv instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nmlp_be = MLPRegressor(\\n    activation=\"tanh\", \\n    solver=\"lbfgs\", \\n    learning_rate=\"invscaling\", \\n    hidden_layer_sizes=(50, 100, 50))\\n\\nsvr_be = SVR(kernel=\"poly\", gamma=\"scale\")\\n\\nlgbm_be = LGBMRegressor(**{\"boosting_type\": \"gbdt\",\\n         \"max_depth\": 5,\\n         \"learning_rate\": 0.12,\\n         \"n_estimators\":100,\\n         \"num_leaves\": 20})\\n\\nrf_be = RandomForestRegressor(criterion=\\'mse\\', n_estimators=850, max_depth=30, min_samples_split=6, random_state=1)\\n\\net_be = ExtraTreesRegressor(**{\\'bootstrap\\': True, \\'max_depth\\': 12, \\'n_estimators\\': 200, \\'random_state\\': 3})\\n\\nparams_be = {\"boosting_type\": \"gbdt\",\"max_depth\": 5,\"learning_rate\": 0.12,\"n_estimators\":100,\"num_leaves\": 20}\\n\\nresults_df_be = pd.DataFrame(columns=[\"Model\", \"CV RMSLE\"])\\n\\nfor name, model in {\"Multi-Layer Perceptron\": mlp_be, \"SVR\": svr_be, \"LightGBM\": lgbm_be, \"ExtraTrees\":et_be, \"RandomForest\":rf_be, \"Stacked Model\": stack_be}.items():\\n\\n    results_df_be = results_df_be.append({\\'Model\\': name, \\'CV RMSLE\\': evaluate_CV(model, X_full_be.values, np.log1p(y_be.values), metric=rmsle_scorer_exp)}, ignore_index = True)\\n    \\nrf_fe = RandomForestRegressor(\\n    criterion=\\'mse\\', \\n    n_estimators=1000, \\n    max_depth=35, \\n    min_samples_split=4, \\n    random_state=1)\\n\\nmlp_fe = MLPRegressor(\\n    activation=\"relu\", \\n    solver=\"lbfgs\", \\n    learning_rate=\"invscaling\", \\n    hidden_layer_sizes=(50, 50))\\n\\nknn_fe = KNeighborsRegressor(\\n    n_neighbors=5, \\n    weights=\\'uniform\\', \\n    metric=\\'manhattan\\')\\n\\n\\net_fe = ExtraTreesRegressor(**{\\n    \\'bootstrap\\': True, \\n    \\'max_depth\\': None, \\n    \\'n_estimators\\': 250, \\n    \\'random_state\\': 3})\\n\\nlgbm_fe = LGBMRegressor(**{\\n    \"boosting_type\": \"gbdt\",\\n    \"max_depth\": 4,\\n    \"learning_rate\": 0.07,\\n    \"n_estimators\":60,\\n    \"num_leaves\": 15})\\n\\nresults_df_fe = pd.DataFrame(columns=[\"Model\", \"CV RMSLE\"])\\n\\nfor name, model in {\"Multi-Layer Perceptron\": mlp_fe, \"KNN\": knn_fe, \"LightGBM\": lgbm_fe, \"ExtraTrees\":et_fe, \"RandomForest\":rf_fe, \"Stacked Model\": stack_fe}.items():\\n\\n    results_df_fe = results_df_fe.append({\\'Model\\': name, \\'CV RMSLE\\': evaluate_CV(model, X_full_fe.values, np.log1p(y_fe.values), metric=rmsle_scorer_exp)}, ignore_index = True)\\n\\nsvr_fe = SVR(kernel=\"poly\", gamma=\"scale\")\\nknn_be = KNeighborsRegressor(n_neighbors=5, weights=\\'distance\\', metric=\\'manhattan\\')\\n\\nnew = pd.merge(results_df_be, results_df_fe, how=\"outer\", on=\"Model\")\\nnew.rename(columns={\"CV RMSLE_x\":\"Bandcap Energy\",\"CV RMSLE_y\":\"Formation Energy\"}, inplace=True)\\nnew.set_value(1, \"Formation Energy\", evaluate_CV(svr_fe, X_full_fe.values, np.log1p(y_fe.values), metric=rmsle_scorer_exp))\\nnew.set_value(6, \"Bandcap Energy\", evaluate_CV(knn_be, X_full_be.values, np.log1p(y_be.values), metric=rmsle_scorer_exp))\\nnew.to_csv(\"results.csv\")\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# commenting out for faster excecution\n",
    "\"\"\"\n",
    "\n",
    "mlp_be = MLPRegressor(\n",
    "    activation=\"tanh\", \n",
    "    solver=\"lbfgs\", \n",
    "    learning_rate=\"invscaling\", \n",
    "    hidden_layer_sizes=(50, 100, 50))\n",
    "\n",
    "svr_be = SVR(kernel=\"poly\", gamma=\"scale\")\n",
    "\n",
    "lgbm_be = LGBMRegressor(**{\"boosting_type\": \"gbdt\",\n",
    "         \"max_depth\": 5,\n",
    "         \"learning_rate\": 0.12,\n",
    "         \"n_estimators\":100,\n",
    "         \"num_leaves\": 20})\n",
    "\n",
    "rf_be = RandomForestRegressor(criterion='mse', n_estimators=850, max_depth=30, min_samples_split=6, random_state=1)\n",
    "\n",
    "et_be = ExtraTreesRegressor(**{'bootstrap': True, 'max_depth': 12, 'n_estimators': 200, 'random_state': 3})\n",
    "\n",
    "params_be = {\"boosting_type\": \"gbdt\",\"max_depth\": 5,\"learning_rate\": 0.12,\"n_estimators\":100,\"num_leaves\": 20}\n",
    "\n",
    "results_df_be = pd.DataFrame(columns=[\"Model\", \"CV RMSLE\"])\n",
    "\n",
    "for name, model in {\"Multi-Layer Perceptron\": mlp_be, \"SVR\": svr_be, \"LightGBM\": lgbm_be, \"ExtraTrees\":et_be, \"RandomForest\":rf_be, \"Stacked Model\": stack_be}.items():\n",
    "\n",
    "    results_df_be = results_df_be.append({'Model': name, 'CV RMSLE': evaluate_CV(model, X_full_be.values, np.log1p(y_be.values), metric=rmsle_scorer_exp)}, ignore_index = True)\n",
    "    \n",
    "rf_fe = RandomForestRegressor(\n",
    "    criterion='mse', \n",
    "    n_estimators=1000, \n",
    "    max_depth=35, \n",
    "    min_samples_split=4, \n",
    "    random_state=1)\n",
    "\n",
    "mlp_fe = MLPRegressor(\n",
    "    activation=\"relu\", \n",
    "    solver=\"lbfgs\", \n",
    "    learning_rate=\"invscaling\", \n",
    "    hidden_layer_sizes=(50, 50))\n",
    "\n",
    "knn_fe = KNeighborsRegressor(\n",
    "    n_neighbors=5, \n",
    "    weights='uniform', \n",
    "    metric='manhattan')\n",
    "\n",
    "\n",
    "et_fe = ExtraTreesRegressor(**{\n",
    "    'bootstrap': True, \n",
    "    'max_depth': None, \n",
    "    'n_estimators': 250, \n",
    "    'random_state': 3})\n",
    "\n",
    "lgbm_fe = LGBMRegressor(**{\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.07,\n",
    "    \"n_estimators\":60,\n",
    "    \"num_leaves\": 15})\n",
    "\n",
    "results_df_fe = pd.DataFrame(columns=[\"Model\", \"CV RMSLE\"])\n",
    "\n",
    "for name, model in {\"Multi-Layer Perceptron\": mlp_fe, \"KNN\": knn_fe, \"LightGBM\": lgbm_fe, \"ExtraTrees\":et_fe, \"RandomForest\":rf_fe, \"Stacked Model\": stack_fe}.items():\n",
    "\n",
    "    results_df_fe = results_df_fe.append({'Model': name, 'CV RMSLE': evaluate_CV(model, X_full_fe.values, np.log1p(y_fe.values), metric=rmsle_scorer_exp)}, ignore_index = True)\n",
    "\n",
    "svr_fe = SVR(kernel=\"poly\", gamma=\"scale\")\n",
    "knn_be = KNeighborsRegressor(n_neighbors=5, weights='distance', metric='manhattan')\n",
    "\n",
    "new = pd.merge(results_df_be, results_df_fe, how=\"outer\", on=\"Model\")\n",
    "new.rename(columns={\"CV RMSLE_x\":\"Bandcap Energy\",\"CV RMSLE_y\":\"Formation Energy\"}, inplace=True)\n",
    "new.set_value(1, \"Formation Energy\", evaluate_CV(svr_fe, X_full_fe.values, np.log1p(y_fe.values), metric=rmsle_scorer_exp))\n",
    "new.set_value(6, \"Bandcap Energy\", evaluate_CV(knn_be, X_full_be.values, np.log1p(y_be.values), metric=rmsle_scorer_exp))\n",
    "new.to_csv(\"results.csv\")\n",
    "\"\"\"\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "new = pd.read_csv(\"results.csv\", delimiter=\",\").drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "fig, ax = subplots()\n",
    "new.sort_values(by=\"Bandcap Energy\").plot.barh(x='Model', ax=ax)\n",
    "ax.set_xlabel(\"RMSLE\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.legend( bbox_to_anchor=(0.9, -0.15), ncol=2)\n",
    "plt.savefig(\"models.png\", dpi=800,bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

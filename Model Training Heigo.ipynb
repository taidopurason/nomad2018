{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for developing preliminary models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "def rmsle(y_true, y_pred, **kwargs):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, np.clip(y_pred, 0, None)))\n",
    "rmsle_scorer = sklearn.metrics.make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "def rmsle_exp(y_true, y_pred, **kwargs):\n",
    "    return np.sqrt(mean_squared_log_error(np.expm1(y_true), np.expm1(y_pred))) \n",
    "rmsle_scorer_exp = sklearn.metrics.make_scorer(rmsle_exp, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def evaluate_CV(model, X, y, metric=rmsle_scorer, n_folds=5, random_state=None):\n",
    "    return -cross_val_score(model, X, y, cv=n_folds, scoring=metric).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data Train data\n",
    "train = pd.read_csv(\"train.csv\", delimiter=\",\")\n",
    "X_additional = pd.read_csv(\"additionalAttributes.csv\", delimiter=\",\").drop(\"Unnamed: 0\", axis=1)\n",
    "X = train.drop([\"formation_energy_ev_natom\", \"bandgap_energy_ev\", \"id\"], axis=1)\n",
    "y_fe = train.formation_energy_ev_natom\n",
    "y_be = train.bandgap_energy_ev\n",
    "X_full = pd.concat([X, X_additional], axis=1)\n",
    "\n",
    "#Read in Test data\n",
    "test = pd.read_csv(\"test.csv\", delimiter=\",\")\n",
    "X_test = test.drop([\"id\"], axis=1)\n",
    "X_test_additional = pd.read_csv(\"additionalAttributesTest.csv\", delimiter=\",\").drop(\"Unnamed: 0\", axis=1)\n",
    "X_full_Test = pd.concat([X_test, X_test_additional], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spacegroup</th>\n",
       "      <th>number_of_total_atoms</th>\n",
       "      <th>percent_atom_al</th>\n",
       "      <th>percent_atom_ga</th>\n",
       "      <th>percent_atom_in</th>\n",
       "      <th>lattice_vector_1_ang</th>\n",
       "      <th>lattice_vector_2_ang</th>\n",
       "      <th>lattice_vector_3_ang</th>\n",
       "      <th>lattice_angle_alpha_degree</th>\n",
       "      <th>lattice_angle_beta_degree</th>\n",
       "      <th>...</th>\n",
       "      <th>distGaO</th>\n",
       "      <th>distInAl</th>\n",
       "      <th>distInGa</th>\n",
       "      <th>distInO</th>\n",
       "      <th>elInt</th>\n",
       "      <th>qAl</th>\n",
       "      <th>qGa</th>\n",
       "      <th>qIn</th>\n",
       "      <th>qO</th>\n",
       "      <th>xEq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.9523</td>\n",
       "      <td>8.5513</td>\n",
       "      <td>9.1775</td>\n",
       "      <td>90.0026</td>\n",
       "      <td>90.0023</td>\n",
       "      <td>...</td>\n",
       "      <td>2.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-41.086176</td>\n",
       "      <td>0.349004</td>\n",
       "      <td>0.345264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.231734</td>\n",
       "      <td>4.896453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.1840</td>\n",
       "      <td>6.1838</td>\n",
       "      <td>23.6287</td>\n",
       "      <td>90.0186</td>\n",
       "      <td>89.9980</td>\n",
       "      <td>...</td>\n",
       "      <td>1.775</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1.775</td>\n",
       "      <td>-38.554098</td>\n",
       "      <td>0.344690</td>\n",
       "      <td>0.347084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.230392</td>\n",
       "      <td>4.905702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>227</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.7510</td>\n",
       "      <td>5.6595</td>\n",
       "      <td>13.9630</td>\n",
       "      <td>90.9688</td>\n",
       "      <td>91.1228</td>\n",
       "      <td>...</td>\n",
       "      <td>1.825</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1.825</td>\n",
       "      <td>-33.957596</td>\n",
       "      <td>0.343019</td>\n",
       "      <td>0.339820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.228280</td>\n",
       "      <td>4.925995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>5.0036</td>\n",
       "      <td>5.0034</td>\n",
       "      <td>13.5318</td>\n",
       "      <td>89.9888</td>\n",
       "      <td>90.0119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025</td>\n",
       "      <td>2.925</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-35.763321</td>\n",
       "      <td>0.337616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.375759</td>\n",
       "      <td>-0.231435</td>\n",
       "      <td>4.898196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>194</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>6.6614</td>\n",
       "      <td>6.6612</td>\n",
       "      <td>24.5813</td>\n",
       "      <td>89.9960</td>\n",
       "      <td>90.0006</td>\n",
       "      <td>...</td>\n",
       "      <td>2.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3.625</td>\n",
       "      <td>2.025</td>\n",
       "      <td>-36.645650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.342521</td>\n",
       "      <td>0.359175</td>\n",
       "      <td>-0.232511</td>\n",
       "      <td>4.869110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2395</td>\n",
       "      <td>33</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.9469</td>\n",
       "      <td>8.5014</td>\n",
       "      <td>9.1298</td>\n",
       "      <td>90.0038</td>\n",
       "      <td>90.0023</td>\n",
       "      <td>...</td>\n",
       "      <td>1.775</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1.775</td>\n",
       "      <td>-39.262887</td>\n",
       "      <td>0.346869</td>\n",
       "      <td>0.345489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.231016</td>\n",
       "      <td>4.905482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2396</td>\n",
       "      <td>167</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.9566</td>\n",
       "      <td>4.9562</td>\n",
       "      <td>13.4178</td>\n",
       "      <td>89.9938</td>\n",
       "      <td>90.0075</td>\n",
       "      <td>...</td>\n",
       "      <td>2.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>2.025</td>\n",
       "      <td>-35.323868</td>\n",
       "      <td>0.345140</td>\n",
       "      <td>0.342118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.228918</td>\n",
       "      <td>4.928134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2397</td>\n",
       "      <td>206</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.2204</td>\n",
       "      <td>9.2200</td>\n",
       "      <td>9.2199</td>\n",
       "      <td>90.0047</td>\n",
       "      <td>90.0046</td>\n",
       "      <td>...</td>\n",
       "      <td>1.975</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1.975</td>\n",
       "      <td>-38.566520</td>\n",
       "      <td>0.364599</td>\n",
       "      <td>0.330046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.230109</td>\n",
       "      <td>4.873503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2398</td>\n",
       "      <td>33</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>10.6529</td>\n",
       "      <td>9.0954</td>\n",
       "      <td>9.7210</td>\n",
       "      <td>90.0015</td>\n",
       "      <td>89.9996</td>\n",
       "      <td>...</td>\n",
       "      <td>2.125</td>\n",
       "      <td>3.375</td>\n",
       "      <td>3.525</td>\n",
       "      <td>2.125</td>\n",
       "      <td>-39.874295</td>\n",
       "      <td>0.335601</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>0.372616</td>\n",
       "      <td>-0.235314</td>\n",
       "      <td>4.842888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2399</td>\n",
       "      <td>206</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>9.0648</td>\n",
       "      <td>9.0641</td>\n",
       "      <td>9.0643</td>\n",
       "      <td>90.0027</td>\n",
       "      <td>90.0037</td>\n",
       "      <td>...</td>\n",
       "      <td>1.975</td>\n",
       "      <td>3.425</td>\n",
       "      <td>4.575</td>\n",
       "      <td>1.975</td>\n",
       "      <td>-39.624552</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>0.326564</td>\n",
       "      <td>0.407318</td>\n",
       "      <td>-0.231068</td>\n",
       "      <td>4.865566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spacegroup  number_of_total_atoms  percent_atom_al  percent_atom_ga  \\\n",
       "0             33                   80.0           0.6250           0.3750   \n",
       "1            194                   80.0           0.6250           0.3750   \n",
       "2            227                   40.0           0.8125           0.1875   \n",
       "3            167                   30.0           0.7500           0.0000   \n",
       "4            194                   80.0           0.0000           0.6250   \n",
       "...          ...                    ...              ...              ...   \n",
       "2395          33                   40.0           0.7500           0.2500   \n",
       "2396         167                   30.0           0.4167           0.5833   \n",
       "2397         206                   80.0           0.4375           0.5625   \n",
       "2398          33                   80.0           0.3125           0.1875   \n",
       "2399         206                   80.0           0.8750           0.0938   \n",
       "\n",
       "      percent_atom_in  lattice_vector_1_ang  lattice_vector_2_ang  \\\n",
       "0              0.0000                9.9523                8.5513   \n",
       "1              0.0000                6.1840                6.1838   \n",
       "2              0.0000                9.7510                5.6595   \n",
       "3              0.2500                5.0036                5.0034   \n",
       "4              0.3750                6.6614                6.6612   \n",
       "...               ...                   ...                   ...   \n",
       "2395           0.0000                4.9469                8.5014   \n",
       "2396           0.0000                4.9566                4.9562   \n",
       "2397           0.0000                9.2204                9.2200   \n",
       "2398           0.5000               10.6529                9.0954   \n",
       "2399           0.0312                9.0648                9.0641   \n",
       "\n",
       "      lattice_vector_3_ang  lattice_angle_alpha_degree  \\\n",
       "0                   9.1775                     90.0026   \n",
       "1                  23.6287                     90.0186   \n",
       "2                  13.9630                     90.9688   \n",
       "3                  13.5318                     89.9888   \n",
       "4                  24.5813                     89.9960   \n",
       "...                    ...                         ...   \n",
       "2395                9.1298                     90.0038   \n",
       "2396               13.4178                     89.9938   \n",
       "2397                9.2199                     90.0047   \n",
       "2398                9.7210                     90.0015   \n",
       "2399                9.0643                     90.0027   \n",
       "\n",
       "      lattice_angle_beta_degree  ...  distGaO  distInAl  distInGa  distInO  \\\n",
       "0                       90.0023  ...    2.025       NaN       NaN      NaN   \n",
       "1                       89.9980  ...    1.775     0.025     0.025    1.775   \n",
       "2                       91.1228  ...    1.825     0.025     0.025    1.825   \n",
       "3                       90.0119  ...    0.025     2.925     0.025    0.025   \n",
       "4                       90.0006  ...    2.025     0.025     3.625    2.025   \n",
       "...                         ...  ...      ...       ...       ...      ...   \n",
       "2395                    90.0023  ...    1.775     0.025     0.025    1.775   \n",
       "2396                    90.0075  ...    2.025     0.025     0.025    2.025   \n",
       "2397                    90.0046  ...    1.975     0.025     0.025    1.975   \n",
       "2398                    89.9996  ...    2.125     3.375     3.525    2.125   \n",
       "2399                    90.0037  ...    1.975     3.425     4.575    1.975   \n",
       "\n",
       "          elInt       qAl       qGa       qIn        qO       xEq  \n",
       "0    -41.086176  0.349004  0.345264       NaN -0.231734  4.896453  \n",
       "1    -38.554098  0.344690  0.347084       NaN -0.230392  4.905702  \n",
       "2    -33.957596  0.343019  0.339820       NaN -0.228280  4.925995  \n",
       "3    -35.763321  0.337616       NaN  0.375759 -0.231435  4.898196  \n",
       "4    -36.645650       NaN  0.342521  0.359175 -0.232511  4.869110  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "2395 -39.262887  0.346869  0.345489       NaN -0.231016  4.905482  \n",
       "2396 -35.323868  0.345140  0.342118       NaN -0.228918  4.928134  \n",
       "2397 -38.566520  0.364599  0.330046       NaN -0.230109  4.873503  \n",
       "2398 -39.874295  0.335601  0.329533  0.372616 -0.235314  4.842888  \n",
       "2399 -39.624552  0.346580  0.326564  0.407318 -0.231068  4.865566  \n",
       "\n",
       "[2400 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove nan values From data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spacegroup', 'number_of_total_atoms', 'percent_atom_al',\n",
       "       'percent_atom_ga', 'percent_atom_in', 'lattice_vector_1_ang',\n",
       "       'lattice_vector_2_ang', 'lattice_vector_3_ang',\n",
       "       'lattice_angle_alpha_degree', 'lattice_angle_beta_degree',\n",
       "       'lattice_angle_gamma_degree', 'Vatom', 'cAlGa', 'cAlIn', 'cAlO',\n",
       "       'cGaAl', 'cGaIn', 'cGaO', 'cInAl', 'cInGa', 'cInO', 'distAlGa',\n",
       "       'distAlIn', 'distAlO', 'distGaAl', 'distGaIn', 'distGaO', 'distInAl',\n",
       "       'distInGa', 'distInO', 'elInt', 'qAl', 'qGa', 'qIn', 'qO', 'xEq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If distance in Nan, it is reasonable to set them to very large value as the atoms are infinitely far from each other\n",
    "* If Coordination number is Nan then it is reasonable to set it as 0, as no atoms are in vicinity of chosen atom\n",
    "* If any of the charges have Nan values it is set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillValues = {'cAlGa':0, \n",
    "              'cAlIn':0, \n",
    "              'cAlO':0,\n",
    "              'cGaAl':0, \n",
    "              'cGaIn':0, \n",
    "              'cGaO':0, \n",
    "              'cInAl':0, \n",
    "              'cInGa':0, \n",
    "              'cInO':0,\n",
    "              'distAlGa':100,\n",
    "              'distAlIn':100,\n",
    "              'distAlO':100,\n",
    "              'distGaAl':100,\n",
    "              'distGaIn':100,\n",
    "              'distGaO':100,\n",
    "              'distInAl':100,\n",
    "              'distInGa':100,\n",
    "              'distInO':100,\n",
    "              'qAl':0, \n",
    "              'qGa':0, \n",
    "              'qIn':0, \n",
    "              'qO':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = X_full.fillna(value=fillValues)\n",
    "X_full_Test = X_full_Test.fillna(value=fillValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize spacegroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Space groups possessing a point of inversion are termed centrosymmetric;\n",
    "#ome space groups have no symmetry element that can change the handedness of an object; these are termed enantiomorphic space groups\n",
    "def setSymmetry(X):\n",
    "    centrosymmetric = []\n",
    "    enantiomorphic = []\n",
    "    groupEnantiomorph = [1]+list(np.arange(3,6,1))+list(np.arange(16,25,1))+list(np.arange(75,81,1))+list(np.arange(89,99,1))+list(np.arange(143,147,1))+list(np.arange(149,156,1))+list(np.arange(168,174,1))+list(np.arange(177,183,1))+list(np.arange(195,200,1))+list(np.arange(207,215,1))\n",
    "    groupCentrosym = [2]+list(np.arange(10,16,1))+list(np.arange(47,75,1))+list(np.arange(83,89,1))+list(np.arange(123,143,1))+list(np.arange(147,149,1))+list(np.arange(162,168,1))+list(np.arange(175,177,1))+list(np.arange(191,195,1))+list(np.arange(200,207,1))+list(np.arange(221,231,1))\n",
    "    for i in range(len(X)):\n",
    "        if(X.spacegroup[i] in groupEnantiomorph):\n",
    "            enantiomorphic+=[1]\n",
    "            centrosymmetric+=[0]\n",
    "        elif(X.spacegroup[i] in groupCentrosym):\n",
    "            enantiomorphic+=[0]\n",
    "            centrosymmetric+=[1]\n",
    "        else:\n",
    "            enantiomorphic+=[0]\n",
    "            centrosymmetric+=[0]\n",
    "    X[\"centroSym\"] = centrosymmetric\n",
    "    X[\"enantioMorph\"] = enantiomorphic\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform encoding\n",
    "def encode_spacegroup(X):\n",
    "    # 1-2 triclinic\n",
    "    # 3-15 monoclinic\n",
    "    # 16-74 orthorhombic\n",
    "    # 75-142 tetragonal\n",
    "    # 143-167 trigonal\n",
    "    # 168-194 hexagonal\n",
    "    # 195-230 cubic\n",
    "    # [ 33 194 227 167 206  12] are the possible spacegroup values\n",
    "    # onehot encode each separately\n",
    "    return pd.get_dummies(X, columns=[\"spacegroup\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = setSymmetry(X_full)\n",
    "X_full = encode_spacegroup(X_full)\n",
    "\n",
    "\n",
    "X_full_Test = setSymmetry(X_full_Test)\n",
    "X_full_Test = encode_spacegroup(X_full_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_total_atoms</th>\n",
       "      <th>percent_atom_al</th>\n",
       "      <th>percent_atom_ga</th>\n",
       "      <th>percent_atom_in</th>\n",
       "      <th>lattice_vector_1_ang</th>\n",
       "      <th>lattice_vector_2_ang</th>\n",
       "      <th>lattice_vector_3_ang</th>\n",
       "      <th>lattice_angle_alpha_degree</th>\n",
       "      <th>lattice_angle_beta_degree</th>\n",
       "      <th>lattice_angle_gamma_degree</th>\n",
       "      <th>...</th>\n",
       "      <th>qO</th>\n",
       "      <th>xEq</th>\n",
       "      <th>centroSym</th>\n",
       "      <th>enantioMorph</th>\n",
       "      <th>spacegroup_12</th>\n",
       "      <th>spacegroup_33</th>\n",
       "      <th>spacegroup_167</th>\n",
       "      <th>spacegroup_194</th>\n",
       "      <th>spacegroup_206</th>\n",
       "      <th>spacegroup_227</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.9523</td>\n",
       "      <td>8.5513</td>\n",
       "      <td>9.1775</td>\n",
       "      <td>90.0026</td>\n",
       "      <td>90.0023</td>\n",
       "      <td>90.0017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231734</td>\n",
       "      <td>4.896453</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.1840</td>\n",
       "      <td>6.1838</td>\n",
       "      <td>23.6287</td>\n",
       "      <td>90.0186</td>\n",
       "      <td>89.9980</td>\n",
       "      <td>120.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230392</td>\n",
       "      <td>4.905702</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.7510</td>\n",
       "      <td>5.6595</td>\n",
       "      <td>13.9630</td>\n",
       "      <td>90.9688</td>\n",
       "      <td>91.1228</td>\n",
       "      <td>30.5185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228280</td>\n",
       "      <td>4.925995</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>5.0036</td>\n",
       "      <td>5.0034</td>\n",
       "      <td>13.5318</td>\n",
       "      <td>89.9888</td>\n",
       "      <td>90.0119</td>\n",
       "      <td>120.0017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231435</td>\n",
       "      <td>4.898196</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>6.6614</td>\n",
       "      <td>6.6612</td>\n",
       "      <td>24.5813</td>\n",
       "      <td>89.9960</td>\n",
       "      <td>90.0006</td>\n",
       "      <td>119.9893</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232511</td>\n",
       "      <td>4.869110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2395</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.9469</td>\n",
       "      <td>8.5014</td>\n",
       "      <td>9.1298</td>\n",
       "      <td>90.0038</td>\n",
       "      <td>90.0023</td>\n",
       "      <td>90.0015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231016</td>\n",
       "      <td>4.905482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2396</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.9566</td>\n",
       "      <td>4.9562</td>\n",
       "      <td>13.4178</td>\n",
       "      <td>89.9938</td>\n",
       "      <td>90.0075</td>\n",
       "      <td>120.0007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228918</td>\n",
       "      <td>4.928134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2397</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.2204</td>\n",
       "      <td>9.2200</td>\n",
       "      <td>9.2199</td>\n",
       "      <td>90.0047</td>\n",
       "      <td>90.0046</td>\n",
       "      <td>89.9954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230109</td>\n",
       "      <td>4.873503</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2398</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>10.6529</td>\n",
       "      <td>9.0954</td>\n",
       "      <td>9.7210</td>\n",
       "      <td>90.0015</td>\n",
       "      <td>89.9996</td>\n",
       "      <td>90.0004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235314</td>\n",
       "      <td>4.842888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2399</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>9.0648</td>\n",
       "      <td>9.0641</td>\n",
       "      <td>9.0643</td>\n",
       "      <td>90.0027</td>\n",
       "      <td>90.0037</td>\n",
       "      <td>89.9987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231068</td>\n",
       "      <td>4.865566</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number_of_total_atoms  percent_atom_al  percent_atom_ga  \\\n",
       "0                      80.0           0.6250           0.3750   \n",
       "1                      80.0           0.6250           0.3750   \n",
       "2                      40.0           0.8125           0.1875   \n",
       "3                      30.0           0.7500           0.0000   \n",
       "4                      80.0           0.0000           0.6250   \n",
       "...                     ...              ...              ...   \n",
       "2395                   40.0           0.7500           0.2500   \n",
       "2396                   30.0           0.4167           0.5833   \n",
       "2397                   80.0           0.4375           0.5625   \n",
       "2398                   80.0           0.3125           0.1875   \n",
       "2399                   80.0           0.8750           0.0938   \n",
       "\n",
       "      percent_atom_in  lattice_vector_1_ang  lattice_vector_2_ang  \\\n",
       "0              0.0000                9.9523                8.5513   \n",
       "1              0.0000                6.1840                6.1838   \n",
       "2              0.0000                9.7510                5.6595   \n",
       "3              0.2500                5.0036                5.0034   \n",
       "4              0.3750                6.6614                6.6612   \n",
       "...               ...                   ...                   ...   \n",
       "2395           0.0000                4.9469                8.5014   \n",
       "2396           0.0000                4.9566                4.9562   \n",
       "2397           0.0000                9.2204                9.2200   \n",
       "2398           0.5000               10.6529                9.0954   \n",
       "2399           0.0312                9.0648                9.0641   \n",
       "\n",
       "      lattice_vector_3_ang  lattice_angle_alpha_degree  \\\n",
       "0                   9.1775                     90.0026   \n",
       "1                  23.6287                     90.0186   \n",
       "2                  13.9630                     90.9688   \n",
       "3                  13.5318                     89.9888   \n",
       "4                  24.5813                     89.9960   \n",
       "...                    ...                         ...   \n",
       "2395                9.1298                     90.0038   \n",
       "2396               13.4178                     89.9938   \n",
       "2397                9.2199                     90.0047   \n",
       "2398                9.7210                     90.0015   \n",
       "2399                9.0643                     90.0027   \n",
       "\n",
       "      lattice_angle_beta_degree  lattice_angle_gamma_degree  ...        qO  \\\n",
       "0                       90.0023                     90.0017  ... -0.231734   \n",
       "1                       89.9980                    120.0025  ... -0.230392   \n",
       "2                       91.1228                     30.5185  ... -0.228280   \n",
       "3                       90.0119                    120.0017  ... -0.231435   \n",
       "4                       90.0006                    119.9893  ... -0.232511   \n",
       "...                         ...                         ...  ...       ...   \n",
       "2395                    90.0023                     90.0015  ... -0.231016   \n",
       "2396                    90.0075                    120.0007  ... -0.228918   \n",
       "2397                    90.0046                     89.9954  ... -0.230109   \n",
       "2398                    89.9996                     90.0004  ... -0.235314   \n",
       "2399                    90.0037                     89.9987  ... -0.231068   \n",
       "\n",
       "           xEq  centroSym  enantioMorph  spacegroup_12  spacegroup_33  \\\n",
       "0     4.896453          0             0              0              1   \n",
       "1     4.905702          1             0              0              0   \n",
       "2     4.925995          1             0              0              0   \n",
       "3     4.898196          1             0              0              0   \n",
       "4     4.869110          1             0              0              0   \n",
       "...        ...        ...           ...            ...            ...   \n",
       "2395  4.905482          0             0              0              1   \n",
       "2396  4.928134          1             0              0              0   \n",
       "2397  4.873503          1             0              0              0   \n",
       "2398  4.842888          0             0              0              1   \n",
       "2399  4.865566          1             0              0              0   \n",
       "\n",
       "      spacegroup_167  spacegroup_194  spacegroup_206  spacegroup_227  \n",
       "0                  0               0               0               0  \n",
       "1                  0               1               0               0  \n",
       "2                  0               0               0               1  \n",
       "3                  1               0               0               0  \n",
       "4                  0               1               0               0  \n",
       "...              ...             ...             ...             ...  \n",
       "2395               0               0               0               0  \n",
       "2396               1               0               0               0  \n",
       "2397               0               0               1               0  \n",
       "2398               0               0               0               0  \n",
       "2399               0               0               1               0  \n",
       "\n",
       "[2400 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale attributes to from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_full_Test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_full)\n",
    "X_fullMinMax = scaler.transform(X_full)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_full_Test)\n",
    "X_full_Test_MinMax = scaler.transform(X_full_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale using Standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_full)\n",
    "\n",
    "X_fullStandard = scaler.transform(X_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate into Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "trainSize = 0.85\n",
    "\n",
    "############## Separate Train into Validation and Train for Formation energy ####################\n",
    "#Without Scaling\n",
    "#X_train_energ, X_val_energ, y_train_energ, y_val_energ = train_test_split(X_full, y_fe, train_size=trainSize, random_state=1)\n",
    "#Min-Max Scaling\n",
    "X_train_energ, X_val_energ, y_train_energ, y_val_energ = train_test_split(X_fullMinMax, y_fe, train_size=trainSize, random_state=1)\n",
    "#Standard scaling\n",
    "#X_train_energ, X_val_energ, y_train_energ, y_val_energ = train_test_split(X_fullStandard, y_fe, train_size=trainSize, random_state=1)\n",
    "\n",
    "\n",
    "############## Separate Train into Validation and Train for Band Gap ####################\n",
    "#Without Scaling\n",
    "#X_train_gap, X_val_gap, y_train_gap, y_val_gap = train_test_split(X_full, y_be, train_size=trainSize, random_state=1)\n",
    "#Min-Max Scaling\n",
    "X_train_gap, X_val_gap, y_train_gap, y_val_gap = train_test_split(X_fullMinMax, y_be, train_size=trainSize, random_state=1)\n",
    "#Standard scaling\n",
    "#X_train_gap, X_val_gap, y_train_gap, y_val_gap = train_test_split(X_fullStandard, y_be, train_size=trainSize, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formation energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### KNN ##############################\n",
    "\n",
    "results_df = pd.DataFrame(columns=['model',\"Neigbors\",\"Metric\",\"weight\",'trainError', 'valError','crossVal'])\n",
    "\n",
    "for metr in [\"manhattan\", \"minkowski\"]:\n",
    "    for i in range(3, 31, 2):\n",
    "        for weight in ['uniform', 'distance']:\n",
    "            knn = KNeighborsRegressor(n_neighbors=i, weights=weight, metric=metr).fit(X_train_energ, y_train_energ)\n",
    "\n",
    "#            print(\"Neighbours \" + str(i))\n",
    "#            print(\"Metric \" + metr)\n",
    "\n",
    "            trainError = rmsle(y_train_energ, knn.predict(X_train_energ))\n",
    "            valError = rmsle(y_val_energ, knn.predict(X_val_energ))\n",
    "            cross_Val = evaluate_CV(knn, X_fullMinMax, y_fe)\n",
    "            results_df = results_df.append({'model': 'KNN',\"Neigbors\":i,\"Metric\":metr,\"weight\":weight,\"trainError\":trainError, 'valError':valError, 'deltaErrors':abs(trainError-valError), 'crossVal':cross_Val}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Neigbors</th>\n",
       "      <th>Metric</th>\n",
       "      <th>weight</th>\n",
       "      <th>trainError</th>\n",
       "      <th>valError</th>\n",
       "      <th>crossVal</th>\n",
       "      <th>deltaErrors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>5</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.026725</td>\n",
       "      <td>0.032796</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>KNN</td>\n",
       "      <td>7</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.028354</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.033543</td>\n",
       "      <td>0.003373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>KNN</td>\n",
       "      <td>9</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.029653</td>\n",
       "      <td>0.032113</td>\n",
       "      <td>0.033791</td>\n",
       "      <td>0.002460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>KNN</td>\n",
       "      <td>11</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.031603</td>\n",
       "      <td>0.033821</td>\n",
       "      <td>0.025217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>KNN</td>\n",
       "      <td>9</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.031832</td>\n",
       "      <td>0.033871</td>\n",
       "      <td>0.025446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>11</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.030733</td>\n",
       "      <td>0.032010</td>\n",
       "      <td>0.033873</td>\n",
       "      <td>0.001278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>KNN</td>\n",
       "      <td>7</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.033888</td>\n",
       "      <td>0.025471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>KNN</td>\n",
       "      <td>13</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.031406</td>\n",
       "      <td>0.033929</td>\n",
       "      <td>0.025020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>KNN</td>\n",
       "      <td>5</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.033049</td>\n",
       "      <td>0.033945</td>\n",
       "      <td>0.026663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>KNN</td>\n",
       "      <td>15</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.031317</td>\n",
       "      <td>0.034028</td>\n",
       "      <td>0.024931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>KNN</td>\n",
       "      <td>13</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.031639</td>\n",
       "      <td>0.032023</td>\n",
       "      <td>0.034119</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>KNN</td>\n",
       "      <td>17</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.031421</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.025035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>KNN</td>\n",
       "      <td>19</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.025340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>KNN</td>\n",
       "      <td>15</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.032155</td>\n",
       "      <td>0.032132</td>\n",
       "      <td>0.034321</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>KNN</td>\n",
       "      <td>21</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.031886</td>\n",
       "      <td>0.034421</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>KNN</td>\n",
       "      <td>3</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.034312</td>\n",
       "      <td>0.034549</td>\n",
       "      <td>0.010110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>KNN</td>\n",
       "      <td>23</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.032094</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>0.025708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>KNN</td>\n",
       "      <td>17</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.032611</td>\n",
       "      <td>0.032425</td>\n",
       "      <td>0.034621</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>KNN</td>\n",
       "      <td>25</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.032208</td>\n",
       "      <td>0.034786</td>\n",
       "      <td>0.025822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>KNN</td>\n",
       "      <td>19</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.034801</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>KNN</td>\n",
       "      <td>9</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.030833</td>\n",
       "      <td>0.033196</td>\n",
       "      <td>0.034807</td>\n",
       "      <td>0.002363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>KNN</td>\n",
       "      <td>7</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.033164</td>\n",
       "      <td>0.034817</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>KNN</td>\n",
       "      <td>27</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.032285</td>\n",
       "      <td>0.034904</td>\n",
       "      <td>0.025899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>KNN</td>\n",
       "      <td>21</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.033250</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>KNN</td>\n",
       "      <td>11</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.031843</td>\n",
       "      <td>0.033511</td>\n",
       "      <td>0.035039</td>\n",
       "      <td>0.001669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>KNN</td>\n",
       "      <td>9</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.033019</td>\n",
       "      <td>0.035051</td>\n",
       "      <td>0.026633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>KNN</td>\n",
       "      <td>5</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.027999</td>\n",
       "      <td>0.034218</td>\n",
       "      <td>0.035079</td>\n",
       "      <td>0.006219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>KNN</td>\n",
       "      <td>11</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.033073</td>\n",
       "      <td>0.035120</td>\n",
       "      <td>0.026687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>KNN</td>\n",
       "      <td>29</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.032564</td>\n",
       "      <td>0.035136</td>\n",
       "      <td>0.026178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>3</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.034517</td>\n",
       "      <td>0.035181</td>\n",
       "      <td>0.028131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>KNN</td>\n",
       "      <td>7</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.033286</td>\n",
       "      <td>0.035193</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>KNN</td>\n",
       "      <td>13</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.033069</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.026683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>KNN</td>\n",
       "      <td>13</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.032509</td>\n",
       "      <td>0.033661</td>\n",
       "      <td>0.035326</td>\n",
       "      <td>0.001152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>KNN</td>\n",
       "      <td>23</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.033725</td>\n",
       "      <td>0.033536</td>\n",
       "      <td>0.035418</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>KNN</td>\n",
       "      <td>15</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.032954</td>\n",
       "      <td>0.035446</td>\n",
       "      <td>0.026568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>KNN</td>\n",
       "      <td>5</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.034333</td>\n",
       "      <td>0.035604</td>\n",
       "      <td>0.027947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>KNN</td>\n",
       "      <td>15</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.033089</td>\n",
       "      <td>0.033722</td>\n",
       "      <td>0.035643</td>\n",
       "      <td>0.000633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>KNN</td>\n",
       "      <td>17</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.033068</td>\n",
       "      <td>0.035647</td>\n",
       "      <td>0.026683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>KNN</td>\n",
       "      <td>25</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.034118</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.035735</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>KNN</td>\n",
       "      <td>19</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.033415</td>\n",
       "      <td>0.035763</td>\n",
       "      <td>0.027029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>KNN</td>\n",
       "      <td>21</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.033609</td>\n",
       "      <td>0.035909</td>\n",
       "      <td>0.027223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>KNN</td>\n",
       "      <td>17</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.033695</td>\n",
       "      <td>0.034061</td>\n",
       "      <td>0.035956</td>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>KNN</td>\n",
       "      <td>27</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.033935</td>\n",
       "      <td>0.035980</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>KNN</td>\n",
       "      <td>19</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.034121</td>\n",
       "      <td>0.034586</td>\n",
       "      <td>0.036119</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>KNN</td>\n",
       "      <td>23</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.033761</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>0.027375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>KNN</td>\n",
       "      <td>25</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.033895</td>\n",
       "      <td>0.036209</td>\n",
       "      <td>0.027509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>KNN</td>\n",
       "      <td>3</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.024773</td>\n",
       "      <td>0.035035</td>\n",
       "      <td>0.036264</td>\n",
       "      <td>0.010262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>KNN</td>\n",
       "      <td>27</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.034015</td>\n",
       "      <td>0.036336</td>\n",
       "      <td>0.027629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>KNN</td>\n",
       "      <td>21</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>0.034878</td>\n",
       "      <td>0.036352</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>KNN</td>\n",
       "      <td>29</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.034944</td>\n",
       "      <td>0.034444</td>\n",
       "      <td>0.036429</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>KNN</td>\n",
       "      <td>29</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.034048</td>\n",
       "      <td>0.036480</td>\n",
       "      <td>0.027662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>KNN</td>\n",
       "      <td>23</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.034851</td>\n",
       "      <td>0.035102</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.000251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>KNN</td>\n",
       "      <td>3</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.035101</td>\n",
       "      <td>0.036801</td>\n",
       "      <td>0.028715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>KNN</td>\n",
       "      <td>25</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.035227</td>\n",
       "      <td>0.035254</td>\n",
       "      <td>0.036878</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>KNN</td>\n",
       "      <td>27</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.035689</td>\n",
       "      <td>0.035420</td>\n",
       "      <td>0.037126</td>\n",
       "      <td>0.000268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>KNN</td>\n",
       "      <td>29</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.035892</td>\n",
       "      <td>0.035541</td>\n",
       "      <td>0.037433</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model Neigbors     Metric    weight  trainError  valError  crossVal  \\\n",
       "2    KNN        5  manhattan   uniform    0.026725  0.032796  0.033299   \n",
       "4    KNN        7  manhattan   uniform    0.028354  0.031726  0.033543   \n",
       "6    KNN        9  manhattan   uniform    0.029653  0.032113  0.033791   \n",
       "9    KNN       11  manhattan  distance    0.006386  0.031603  0.033821   \n",
       "7    KNN        9  manhattan  distance    0.006386  0.031832  0.033871   \n",
       "8    KNN       11  manhattan   uniform    0.030733  0.032010  0.033873   \n",
       "5    KNN        7  manhattan  distance    0.006386  0.031857  0.033888   \n",
       "11   KNN       13  manhattan  distance    0.006386  0.031406  0.033929   \n",
       "3    KNN        5  manhattan  distance    0.006386  0.033049  0.033945   \n",
       "13   KNN       15  manhattan  distance    0.006386  0.031317  0.034028   \n",
       "10   KNN       13  manhattan   uniform    0.031639  0.032023  0.034119   \n",
       "15   KNN       17  manhattan  distance    0.006386  0.031421  0.034194   \n",
       "17   KNN       19  manhattan  distance    0.006386  0.031726  0.034300   \n",
       "12   KNN       15  manhattan   uniform    0.032155  0.032132  0.034321   \n",
       "19   KNN       21  manhattan  distance    0.006386  0.031886  0.034421   \n",
       "0    KNN        3  manhattan   uniform    0.024202  0.034312  0.034549   \n",
       "21   KNN       23  manhattan  distance    0.006386  0.032094  0.034594   \n",
       "14   KNN       17  manhattan   uniform    0.032611  0.032425  0.034621   \n",
       "23   KNN       25  manhattan  distance    0.006386  0.032208  0.034786   \n",
       "16   KNN       19  manhattan   uniform    0.032945  0.033045  0.034801   \n",
       "34   KNN        9  minkowski   uniform    0.030833  0.033196  0.034807   \n",
       "32   KNN        7  minkowski   uniform    0.029788  0.033164  0.034817   \n",
       "25   KNN       27  manhattan  distance    0.006386  0.032285  0.034904   \n",
       "18   KNN       21  manhattan   uniform    0.033424  0.033250  0.035034   \n",
       "36   KNN       11  minkowski   uniform    0.031843  0.033511  0.035039   \n",
       "35   KNN        9  minkowski  distance    0.006386  0.033019  0.035051   \n",
       "30   KNN        5  minkowski   uniform    0.027999  0.034218  0.035079   \n",
       "37   KNN       11  minkowski  distance    0.006386  0.033073  0.035120   \n",
       "27   KNN       29  manhattan  distance    0.006386  0.032564  0.035136   \n",
       "1    KNN        3  manhattan  distance    0.006386  0.034517  0.035181   \n",
       "33   KNN        7  minkowski  distance    0.006386  0.033286  0.035193   \n",
       "39   KNN       13  minkowski  distance    0.006386  0.033069  0.035284   \n",
       "38   KNN       13  minkowski   uniform    0.032509  0.033661  0.035326   \n",
       "20   KNN       23  manhattan   uniform    0.033725  0.033536  0.035418   \n",
       "41   KNN       15  minkowski  distance    0.006386  0.032954  0.035446   \n",
       "31   KNN        5  minkowski  distance    0.006386  0.034333  0.035604   \n",
       "40   KNN       15  minkowski   uniform    0.033089  0.033722  0.035643   \n",
       "43   KNN       17  minkowski  distance    0.006386  0.033068  0.035647   \n",
       "22   KNN       25  manhattan   uniform    0.034118  0.033708  0.035735   \n",
       "45   KNN       19  minkowski  distance    0.006386  0.033415  0.035763   \n",
       "47   KNN       21  minkowski  distance    0.006386  0.033609  0.035909   \n",
       "42   KNN       17  minkowski   uniform    0.033695  0.034061  0.035956   \n",
       "24   KNN       27  manhattan   uniform    0.034507  0.033935  0.035980   \n",
       "44   KNN       19  minkowski   uniform    0.034121  0.034586  0.036119   \n",
       "49   KNN       23  minkowski  distance    0.006386  0.033761  0.036120   \n",
       "51   KNN       25  minkowski  distance    0.006386  0.033895  0.036209   \n",
       "28   KNN        3  minkowski   uniform    0.024773  0.035035  0.036264   \n",
       "53   KNN       27  minkowski  distance    0.006386  0.034015  0.036336   \n",
       "46   KNN       21  minkowski   uniform    0.034462  0.034878  0.036352   \n",
       "26   KNN       29  manhattan   uniform    0.034944  0.034444  0.036429   \n",
       "55   KNN       29  minkowski  distance    0.006386  0.034048  0.036480   \n",
       "48   KNN       23  minkowski   uniform    0.034851  0.035102  0.036700   \n",
       "29   KNN        3  minkowski  distance    0.006386  0.035101  0.036801   \n",
       "50   KNN       25  minkowski   uniform    0.035227  0.035254  0.036878   \n",
       "52   KNN       27  minkowski   uniform    0.035689  0.035420  0.037126   \n",
       "54   KNN       29  minkowski   uniform    0.035892  0.035541  0.037433   \n",
       "\n",
       "    deltaErrors  \n",
       "2      0.006071  \n",
       "4      0.003373  \n",
       "6      0.002460  \n",
       "9      0.025217  \n",
       "7      0.025446  \n",
       "8      0.001278  \n",
       "5      0.025471  \n",
       "11     0.025020  \n",
       "3      0.026663  \n",
       "13     0.024931  \n",
       "10     0.000384  \n",
       "15     0.025035  \n",
       "17     0.025340  \n",
       "12     0.000023  \n",
       "19     0.025500  \n",
       "0      0.010110  \n",
       "21     0.025708  \n",
       "14     0.000186  \n",
       "23     0.025822  \n",
       "16     0.000100  \n",
       "34     0.002363  \n",
       "32     0.003376  \n",
       "25     0.025899  \n",
       "18     0.000174  \n",
       "36     0.001669  \n",
       "35     0.026633  \n",
       "30     0.006219  \n",
       "37     0.026687  \n",
       "27     0.026178  \n",
       "1      0.028131  \n",
       "33     0.026900  \n",
       "39     0.026683  \n",
       "38     0.001152  \n",
       "20     0.000188  \n",
       "41     0.026568  \n",
       "31     0.027947  \n",
       "40     0.000633  \n",
       "43     0.026683  \n",
       "22     0.000410  \n",
       "45     0.027029  \n",
       "47     0.027223  \n",
       "42     0.000366  \n",
       "24     0.000572  \n",
       "44     0.000465  \n",
       "49     0.027375  \n",
       "51     0.027509  \n",
       "28     0.010262  \n",
       "53     0.027629  \n",
       "46     0.000417  \n",
       "26     0.000500  \n",
       "55     0.027662  \n",
       "48     0.000251  \n",
       "29     0.028715  \n",
       "50     0.000027  \n",
       "52     0.000268  \n",
       "54     0.000350  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by=[\"crossVal\",\"valError\", \"deltaErrors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestKnnFe = KNeighborsRegressor(n_neighbors=5, weights='uniform', metric='manhattan').fit(X_train_energ, y_train_energ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN\t5\tmanhattan\tuniform\t0.026725\t0.032796\t0.033299\t0.006071"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Band Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### KNN ##############################\n",
    "results_df = pd.DataFrame(columns=['model',\"Neigbors\",\"Metric\",\"weight\",'trainError', 'valError'])\n",
    "\n",
    "for metr in [\"manhattan\", \"minkowski\"]:\n",
    "    for i in range(3, 31, 2):\n",
    "        for weight in ['uniform', 'distance']:\n",
    "            knn = KNeighborsRegressor(n_neighbors=i, weights=weight, metric=metr).fit(X_train_gap, y_train_gap)\n",
    "\n",
    "#            print(\"Neighbours \" + str(i))\n",
    "#            print(\"Metric \" + metr)\n",
    "\n",
    "            trainError = rmsle(y_train_gap, knn.predict(X_train_gap))\n",
    "            valError = rmsle(y_val_gap, knn.predict(X_val_gap))\n",
    "            cross_Val = evaluate_CV(knn, X_fullMinMax, y_be)\n",
    "            results_df = results_df.append({'model': 'KNN',\"Neigbors\":i,\"Metric\":metr,\"weight\":weight,\"trainError\":trainError, 'valError':valError, 'deltaErrors':abs(trainError-valError), 'crossVal':cross_Val}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Neigbors</th>\n",
       "      <th>Metric</th>\n",
       "      <th>weight</th>\n",
       "      <th>trainError</th>\n",
       "      <th>valError</th>\n",
       "      <th>crossVal</th>\n",
       "      <th>deltaErrors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>KNN</td>\n",
       "      <td>5</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.086016</td>\n",
       "      <td>0.096120</td>\n",
       "      <td>0.077132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>5</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>0.087256</td>\n",
       "      <td>0.097157</td>\n",
       "      <td>0.010296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>KNN</td>\n",
       "      <td>9</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.085056</td>\n",
       "      <td>0.097548</td>\n",
       "      <td>0.076172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>KNN</td>\n",
       "      <td>7</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.084873</td>\n",
       "      <td>0.097794</td>\n",
       "      <td>0.075989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>KNN</td>\n",
       "      <td>11</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.085306</td>\n",
       "      <td>0.098030</td>\n",
       "      <td>0.076422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>KNN</td>\n",
       "      <td>13</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.087785</td>\n",
       "      <td>0.099244</td>\n",
       "      <td>0.078901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>3</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.089373</td>\n",
       "      <td>0.099906</td>\n",
       "      <td>0.080489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>KNN</td>\n",
       "      <td>3</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.070379</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>0.100146</td>\n",
       "      <td>0.020666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>KNN</td>\n",
       "      <td>15</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.089261</td>\n",
       "      <td>0.100634</td>\n",
       "      <td>0.080377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>KNN</td>\n",
       "      <td>7</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.083849</td>\n",
       "      <td>0.087318</td>\n",
       "      <td>0.100650</td>\n",
       "      <td>0.003469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>KNN</td>\n",
       "      <td>9</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.088817</td>\n",
       "      <td>0.088883</td>\n",
       "      <td>0.101815</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>KNN</td>\n",
       "      <td>17</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.091465</td>\n",
       "      <td>0.102217</td>\n",
       "      <td>0.082581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>KNN</td>\n",
       "      <td>7</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.090050</td>\n",
       "      <td>0.102260</td>\n",
       "      <td>0.081166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>KNN</td>\n",
       "      <td>9</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.092513</td>\n",
       "      <td>0.102972</td>\n",
       "      <td>0.083629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>KNN</td>\n",
       "      <td>19</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.093828</td>\n",
       "      <td>0.103320</td>\n",
       "      <td>0.084944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>11</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.092397</td>\n",
       "      <td>0.090753</td>\n",
       "      <td>0.103355</td>\n",
       "      <td>0.001644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>KNN</td>\n",
       "      <td>11</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.093680</td>\n",
       "      <td>0.103433</td>\n",
       "      <td>0.084796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>KNN</td>\n",
       "      <td>5</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.093879</td>\n",
       "      <td>0.103577</td>\n",
       "      <td>0.084995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>KNN</td>\n",
       "      <td>5</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.083385</td>\n",
       "      <td>0.094814</td>\n",
       "      <td>0.104730</td>\n",
       "      <td>0.011429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>KNN</td>\n",
       "      <td>21</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.095308</td>\n",
       "      <td>0.104738</td>\n",
       "      <td>0.086424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>KNN</td>\n",
       "      <td>7</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.087721</td>\n",
       "      <td>0.091650</td>\n",
       "      <td>0.104773</td>\n",
       "      <td>0.003929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>KNN</td>\n",
       "      <td>13</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.095317</td>\n",
       "      <td>0.104842</td>\n",
       "      <td>0.086433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>KNN</td>\n",
       "      <td>13</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.096406</td>\n",
       "      <td>0.095765</td>\n",
       "      <td>0.105653</td>\n",
       "      <td>0.000641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>KNN</td>\n",
       "      <td>15</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.106037</td>\n",
       "      <td>0.088338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>KNN</td>\n",
       "      <td>23</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.097050</td>\n",
       "      <td>0.106171</td>\n",
       "      <td>0.088166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>KNN</td>\n",
       "      <td>3</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.099841</td>\n",
       "      <td>0.106375</td>\n",
       "      <td>0.090957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>KNN</td>\n",
       "      <td>3</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.073877</td>\n",
       "      <td>0.100882</td>\n",
       "      <td>0.106668</td>\n",
       "      <td>0.027005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>KNN</td>\n",
       "      <td>9</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.092914</td>\n",
       "      <td>0.096173</td>\n",
       "      <td>0.107115</td>\n",
       "      <td>0.003259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>KNN</td>\n",
       "      <td>17</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.098689</td>\n",
       "      <td>0.107230</td>\n",
       "      <td>0.089805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>KNN</td>\n",
       "      <td>25</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.098799</td>\n",
       "      <td>0.107275</td>\n",
       "      <td>0.089915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>KNN</td>\n",
       "      <td>15</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.099518</td>\n",
       "      <td>0.099197</td>\n",
       "      <td>0.108072</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>KNN</td>\n",
       "      <td>11</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.097202</td>\n",
       "      <td>0.099095</td>\n",
       "      <td>0.108332</td>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>KNN</td>\n",
       "      <td>27</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.100201</td>\n",
       "      <td>0.108516</td>\n",
       "      <td>0.091317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>KNN</td>\n",
       "      <td>19</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.100413</td>\n",
       "      <td>0.108729</td>\n",
       "      <td>0.091530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>KNN</td>\n",
       "      <td>29</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.102087</td>\n",
       "      <td>0.110110</td>\n",
       "      <td>0.093203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>KNN</td>\n",
       "      <td>21</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.101778</td>\n",
       "      <td>0.110131</td>\n",
       "      <td>0.092894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>KNN</td>\n",
       "      <td>13</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.100687</td>\n",
       "      <td>0.102288</td>\n",
       "      <td>0.110580</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>KNN</td>\n",
       "      <td>17</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.102620</td>\n",
       "      <td>0.102651</td>\n",
       "      <td>0.110726</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>KNN</td>\n",
       "      <td>23</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.103111</td>\n",
       "      <td>0.111479</td>\n",
       "      <td>0.094227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>KNN</td>\n",
       "      <td>19</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.104944</td>\n",
       "      <td>0.106313</td>\n",
       "      <td>0.112557</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>KNN</td>\n",
       "      <td>25</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.104761</td>\n",
       "      <td>0.112828</td>\n",
       "      <td>0.095877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>KNN</td>\n",
       "      <td>15</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.103885</td>\n",
       "      <td>0.106210</td>\n",
       "      <td>0.112914</td>\n",
       "      <td>0.002325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>KNN</td>\n",
       "      <td>27</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.106575</td>\n",
       "      <td>0.114443</td>\n",
       "      <td>0.097691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>KNN</td>\n",
       "      <td>17</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.106576</td>\n",
       "      <td>0.108750</td>\n",
       "      <td>0.114582</td>\n",
       "      <td>0.002174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>KNN</td>\n",
       "      <td>21</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.107620</td>\n",
       "      <td>0.108146</td>\n",
       "      <td>0.114756</td>\n",
       "      <td>0.000526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>KNN</td>\n",
       "      <td>29</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.109227</td>\n",
       "      <td>0.116001</td>\n",
       "      <td>0.100343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>KNN</td>\n",
       "      <td>19</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.109353</td>\n",
       "      <td>0.110250</td>\n",
       "      <td>0.116646</td>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>KNN</td>\n",
       "      <td>23</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.109502</td>\n",
       "      <td>0.110397</td>\n",
       "      <td>0.117147</td>\n",
       "      <td>0.000895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>KNN</td>\n",
       "      <td>21</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.111736</td>\n",
       "      <td>0.111854</td>\n",
       "      <td>0.118497</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>KNN</td>\n",
       "      <td>25</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>0.112570</td>\n",
       "      <td>0.118932</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>KNN</td>\n",
       "      <td>23</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.113387</td>\n",
       "      <td>0.113350</td>\n",
       "      <td>0.120458</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>KNN</td>\n",
       "      <td>27</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.114018</td>\n",
       "      <td>0.114749</td>\n",
       "      <td>0.121119</td>\n",
       "      <td>0.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>KNN</td>\n",
       "      <td>25</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.115609</td>\n",
       "      <td>0.115256</td>\n",
       "      <td>0.122483</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>KNN</td>\n",
       "      <td>29</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.116778</td>\n",
       "      <td>0.117699</td>\n",
       "      <td>0.123968</td>\n",
       "      <td>0.000921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>KNN</td>\n",
       "      <td>27</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.117971</td>\n",
       "      <td>0.117755</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>KNN</td>\n",
       "      <td>29</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.120670</td>\n",
       "      <td>0.121637</td>\n",
       "      <td>0.127538</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model Neigbors     Metric    weight  trainError  valError  crossVal  \\\n",
       "3    KNN        5  manhattan  distance    0.008884  0.086016  0.096120   \n",
       "2    KNN        5  manhattan   uniform    0.076959  0.087256  0.097157   \n",
       "7    KNN        9  manhattan  distance    0.008884  0.085056  0.097548   \n",
       "5    KNN        7  manhattan  distance    0.008884  0.084873  0.097794   \n",
       "9    KNN       11  manhattan  distance    0.008884  0.085306  0.098030   \n",
       "11   KNN       13  manhattan  distance    0.008884  0.087785  0.099244   \n",
       "1    KNN        3  manhattan  distance    0.008884  0.089373  0.099906   \n",
       "0    KNN        3  manhattan   uniform    0.070379  0.091045  0.100146   \n",
       "13   KNN       15  manhattan  distance    0.008884  0.089261  0.100634   \n",
       "4    KNN        7  manhattan   uniform    0.083849  0.087318  0.100650   \n",
       "6    KNN        9  manhattan   uniform    0.088817  0.088883  0.101815   \n",
       "15   KNN       17  manhattan  distance    0.008884  0.091465  0.102217   \n",
       "33   KNN        7  minkowski  distance    0.008884  0.090050  0.102260   \n",
       "35   KNN        9  minkowski  distance    0.008884  0.092513  0.102972   \n",
       "17   KNN       19  manhattan  distance    0.008884  0.093828  0.103320   \n",
       "8    KNN       11  manhattan   uniform    0.092397  0.090753  0.103355   \n",
       "37   KNN       11  minkowski  distance    0.008884  0.093680  0.103433   \n",
       "31   KNN        5  minkowski  distance    0.008884  0.093879  0.103577   \n",
       "30   KNN        5  minkowski   uniform    0.083385  0.094814  0.104730   \n",
       "19   KNN       21  manhattan  distance    0.008884  0.095308  0.104738   \n",
       "32   KNN        7  minkowski   uniform    0.087721  0.091650  0.104773   \n",
       "39   KNN       13  minkowski  distance    0.008884  0.095317  0.104842   \n",
       "10   KNN       13  manhattan   uniform    0.096406  0.095765  0.105653   \n",
       "41   KNN       15  minkowski  distance    0.008884  0.097222  0.106037   \n",
       "21   KNN       23  manhattan  distance    0.008884  0.097050  0.106171   \n",
       "29   KNN        3  minkowski  distance    0.008884  0.099841  0.106375   \n",
       "28   KNN        3  minkowski   uniform    0.073877  0.100882  0.106668   \n",
       "34   KNN        9  minkowski   uniform    0.092914  0.096173  0.107115   \n",
       "43   KNN       17  minkowski  distance    0.008884  0.098689  0.107230   \n",
       "23   KNN       25  manhattan  distance    0.008884  0.098799  0.107275   \n",
       "12   KNN       15  manhattan   uniform    0.099518  0.099197  0.108072   \n",
       "36   KNN       11  minkowski   uniform    0.097202  0.099095  0.108332   \n",
       "25   KNN       27  manhattan  distance    0.008884  0.100201  0.108516   \n",
       "45   KNN       19  minkowski  distance    0.008884  0.100413  0.108729   \n",
       "27   KNN       29  manhattan  distance    0.008884  0.102087  0.110110   \n",
       "47   KNN       21  minkowski  distance    0.008884  0.101778  0.110131   \n",
       "38   KNN       13  minkowski   uniform    0.100687  0.102288  0.110580   \n",
       "14   KNN       17  manhattan   uniform    0.102620  0.102651  0.110726   \n",
       "49   KNN       23  minkowski  distance    0.008884  0.103111  0.111479   \n",
       "16   KNN       19  manhattan   uniform    0.104944  0.106313  0.112557   \n",
       "51   KNN       25  minkowski  distance    0.008884  0.104761  0.112828   \n",
       "40   KNN       15  minkowski   uniform    0.103885  0.106210  0.112914   \n",
       "53   KNN       27  minkowski  distance    0.008884  0.106575  0.114443   \n",
       "42   KNN       17  minkowski   uniform    0.106576  0.108750  0.114582   \n",
       "18   KNN       21  manhattan   uniform    0.107620  0.108146  0.114756   \n",
       "55   KNN       29  minkowski  distance    0.008884  0.109227  0.116001   \n",
       "44   KNN       19  minkowski   uniform    0.109353  0.110250  0.116646   \n",
       "20   KNN       23  manhattan   uniform    0.109502  0.110397  0.117147   \n",
       "46   KNN       21  minkowski   uniform    0.111736  0.111854  0.118497   \n",
       "22   KNN       25  manhattan   uniform    0.111900  0.112570  0.118932   \n",
       "48   KNN       23  minkowski   uniform    0.113387  0.113350  0.120458   \n",
       "24   KNN       27  manhattan   uniform    0.114018  0.114749  0.121119   \n",
       "50   KNN       25  minkowski   uniform    0.115609  0.115256  0.122483   \n",
       "26   KNN       29  manhattan   uniform    0.116778  0.117699  0.123968   \n",
       "52   KNN       27  minkowski   uniform    0.117971  0.117755  0.125000   \n",
       "54   KNN       29  minkowski   uniform    0.120670  0.121637  0.127538   \n",
       "\n",
       "    deltaErrors  \n",
       "3      0.077132  \n",
       "2      0.010296  \n",
       "7      0.076172  \n",
       "5      0.075989  \n",
       "9      0.076422  \n",
       "11     0.078901  \n",
       "1      0.080489  \n",
       "0      0.020666  \n",
       "13     0.080377  \n",
       "4      0.003469  \n",
       "6      0.000066  \n",
       "15     0.082581  \n",
       "33     0.081166  \n",
       "35     0.083629  \n",
       "17     0.084944  \n",
       "8      0.001644  \n",
       "37     0.084796  \n",
       "31     0.084995  \n",
       "30     0.011429  \n",
       "19     0.086424  \n",
       "32     0.003929  \n",
       "39     0.086433  \n",
       "10     0.000641  \n",
       "41     0.088338  \n",
       "21     0.088166  \n",
       "29     0.090957  \n",
       "28     0.027005  \n",
       "34     0.003259  \n",
       "43     0.089805  \n",
       "23     0.089915  \n",
       "12     0.000321  \n",
       "36     0.001894  \n",
       "25     0.091317  \n",
       "45     0.091530  \n",
       "27     0.093203  \n",
       "47     0.092894  \n",
       "38     0.001601  \n",
       "14     0.000030  \n",
       "49     0.094227  \n",
       "16     0.001369  \n",
       "51     0.095877  \n",
       "40     0.002325  \n",
       "53     0.097691  \n",
       "42     0.002174  \n",
       "18     0.000526  \n",
       "55     0.100343  \n",
       "44     0.000897  \n",
       "20     0.000895  \n",
       "46     0.000118  \n",
       "22     0.000670  \n",
       "48     0.000037  \n",
       "24     0.000731  \n",
       "50     0.000353  \n",
       "26     0.000921  \n",
       "52     0.000216  \n",
       "54     0.000967  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by=[\"crossVal\",\"valError\", \"deltaErrors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN\t5\tmanhattan\tdistance\t0.008884\t0.086016\t0.096120\t0.077132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestKnnGap = KNeighborsRegressor(n_neighbors=5, weights='distance', metric='manhattan').fit(X_train_gap, y_train_gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formation energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: poly\n",
      "Gamma: scale\n",
      "Training error: 0.04575511989007159\n",
      "Validation error: 0.046548858967812815\n",
      "Cross Val: 0.0468249760291898\n",
      "Kernel: poly\n",
      "Gamma: auto\n",
      "Training error: 0.05368859105287863\n",
      "Validation error: 0.053315590896120375\n",
      "Cross Val: 0.054080919423228756\n",
      "Kernel: rbf\n",
      "Gamma: scale\n",
      "Training error: 0.04655858501114167\n",
      "Validation error: 0.04670380970846281\n",
      "Cross Val: 0.04760095925247003\n",
      "Kernel: rbf\n",
      "Gamma: auto\n",
      "Training error: 0.04692385157175928\n",
      "Validation error: 0.0462874440934817\n",
      "Cross Val: 0.04790557016826317\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################ SVR ##################################\n",
    "\n",
    "kernels = ['poly', 'rbf']\n",
    "gammas=['scale', 'auto']\n",
    "for ker in kernels:\n",
    "    for gam in gammas:\n",
    "        svm = SVR(kernel=ker, gamma=gam).fit(X_train_energ, y_train_energ)\n",
    "        trainError = rmsle(y_train_energ, abs(svm.predict(X_train_energ)))\n",
    "        valError = rmsle(y_val_energ, abs(svm.predict(X_val_energ)))\n",
    "        cross_Val = evaluate_CV(svm, X_fullMinMax, y_fe)\n",
    "        print(\"Kernel: \" + ker)\n",
    "        print(\"Gamma: \"+ gam)\n",
    "        print(\"Training error: \"+str(trainError))\n",
    "        print(\"Validation error: \"+ str(valError))\n",
    "        print(\"Cross Val: \"+ str(cross_Val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel: rbf\n",
    "Gamma: scale\n",
    "Training error: 0.04645671148891898\n",
    "Validation error: 0.04642970080484417"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Band gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "Kernel: poly\n",
      "Gamma: scale\n",
      "Training error: 0.07647495018153275\n",
      "Validation error: 0.0714004739716549\n",
      "Cross Val: 0.08448192991361378\n",
      "#########################\n",
      "Kernel: poly\n",
      "Gamma: auto\n",
      "Training error: 0.16001985199198773\n",
      "Validation error: 0.16198828270740068\n",
      "Cross Val: 0.16357661238014196\n",
      "#########################\n",
      "Kernel: rbf\n",
      "Gamma: scale\n",
      "Training error: 0.08178966104416957\n",
      "Validation error: 0.07406221371391183\n",
      "Cross Val: 0.08694838534130755\n",
      "#########################\n",
      "Kernel: rbf\n",
      "Gamma: auto\n",
      "Training error: 0.09706518792476887\n",
      "Validation error: 0.08451282750292406\n",
      "Cross Val: 0.09767289649953019\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################ SVR ##################################\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "kernels = ['poly', 'rbf']\n",
    "gammas=['scale', 'auto']\n",
    "for ker in kernels:\n",
    "    for gam in gammas:\n",
    "        svm = SVR(kernel=ker, gamma=gam).fit(X_train_gap, y_train_gap)\n",
    "        trainError = rmsle(y_train_gap, abs(svm.predict(X_train_gap)))\n",
    "        valError = rmsle(y_val_gap, abs(svm.predict(X_val_gap)))\n",
    "        cross_Val = evaluate_CV(svm, X_fullMinMax, y_be)\n",
    "        print(\"#########################\")\n",
    "        print(\"Kernel: \" + ker)\n",
    "        print(\"Gamma: \"+ gam)\n",
    "        print(\"Training error: \"+str(trainError))\n",
    "        print(\"Validation error: \"+ str(valError))\n",
    "        print(\"Cross Val: \"+ str(cross_Val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel: poly\n",
    "Gamma: scale\n",
    "Training error: 0.07584564240632702\n",
    "Validation error: 0.07156753875472792"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formation energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-64006f79c470>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmax_d\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmax_depths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmin_ss\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmin_samples_splits\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_ss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_energ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_energ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[0mtrainError\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_energ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_energ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mvalError\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val_energ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_energ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1155\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1158\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############### Random Forest ##############################\n",
    "\n",
    "n_estimatorss = [650,750,850,1000]\n",
    "max_depths=[30,35,40,45]\n",
    "min_samples_splits=[4,6,8]\n",
    "seeds = [1]\n",
    "results_df = pd.DataFrame(columns=['model',\"seed\",\"n_estimators\",\"max_depth\",\"min_samples_split\",'TrainError', 'ValError', 'deltaErrors'])\n",
    "\n",
    "for seed in seeds:\n",
    "    for n_estimator in n_estimatorss:\n",
    "        for max_d in max_depths:\n",
    "            for min_ss in min_samples_splits:\n",
    "                rf = RandomForestRegressor(criterion='mse', n_estimators=n_estimator, max_depth=max_d, min_samples_split=min_ss, random_state=seed).fit(X_train_energ, y_train_energ)\n",
    "                trainError = rmsle(y_train_energ, (rf.predict(X_train_energ)))\n",
    "                valError = rmsle(y_val_energ, (rf.predict(X_val_energ)))\n",
    "\n",
    "                cross_Val = evaluate_CV(rf, X_fullMinMax, y_fe)\n",
    "                results_df = results_df.append({'model': 'RF',\"seed\":seed,\"n_estimators\":n_estimator,\"max_depth\":max_d,\"min_samples_split\":min_ss,\"TrainError\":trainError, 'ValError':valError, 'deltaErrors':abs(trainError-valError),'crossVal':cross_Val}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by=[\"crossVal\",\"ValError\", \"deltaErrors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39\tRF\t1\t1000\t35\t4\t0.013313\t0.030207\t0.016894\t0.031341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestRfFe = RandomForestRegressor(criterion='mse', n_estimators=1000, max_depth=35, min_samples_split=4, random_state=1).fit(X_train_energ, y_train_energ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Band Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Random Forest ##############################\n",
    "\n",
    "n_estimatorss = [650,750,850,1000]\n",
    "max_depths=[30,35,40,45,50]\n",
    "min_samples_splits=[4,6,8]\n",
    "seeds = [1]\n",
    "results_df = pd.DataFrame(columns=['model',\"seed\",\"n_estimators\",\"max_depth\",\"min_samples_split\",'TrainError', 'ValError', 'deltaErrors'])\n",
    "\n",
    "for seed in seeds:\n",
    "    for n_estimator in n_estimatorss:\n",
    "        for max_d in max_depths:\n",
    "            for min_ss in min_samples_splits:\n",
    "                rf = RandomForestRegressor(criterion='mse', n_estimators=n_estimator, max_depth=max_d, min_samples_split=min_ss, random_state=seed).fit(X_train_gap, y_train_gap)\n",
    "                trainError = rmsle(y_train_gap, (rf.predict(X_train_gap)))\n",
    "                valError = rmsle(y_val_gap, (rf.predict(X_val_gap)))\n",
    "                cross_Val = evaluate_CV(rf, X_fullMinMax, y_be)\n",
    "                results_df = results_df.append({'model': 'RF',\"seed\":seed,\"n_estimators\":n_estimator,\"max_depth\":max_d,\"min_samples_split\":min_ss,\"TrainError\":trainError, 'ValError':valError, 'deltaErrors':abs(trainError-valError),'crossVal':cross_Val}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>TrainError</th>\n",
       "      <th>ValError</th>\n",
       "      <th>deltaErrors</th>\n",
       "      <th>crossVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.041993</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.038494</td>\n",
       "      <td>0.089325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0.041993</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.038494</td>\n",
       "      <td>0.089325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>0.041993</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.038494</td>\n",
       "      <td>0.089325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0.041993</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.038494</td>\n",
       "      <td>0.089325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.041993</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.038494</td>\n",
       "      <td>0.089325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038443</td>\n",
       "      <td>0.080184</td>\n",
       "      <td>0.041741</td>\n",
       "      <td>0.089339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038443</td>\n",
       "      <td>0.080184</td>\n",
       "      <td>0.041741</td>\n",
       "      <td>0.089339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038443</td>\n",
       "      <td>0.080184</td>\n",
       "      <td>0.041741</td>\n",
       "      <td>0.089339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038443</td>\n",
       "      <td>0.080184</td>\n",
       "      <td>0.041741</td>\n",
       "      <td>0.089339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038444</td>\n",
       "      <td>0.080191</td>\n",
       "      <td>0.041747</td>\n",
       "      <td>0.089339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038497</td>\n",
       "      <td>0.080094</td>\n",
       "      <td>0.041598</td>\n",
       "      <td>0.089356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038497</td>\n",
       "      <td>0.080094</td>\n",
       "      <td>0.041598</td>\n",
       "      <td>0.089356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038497</td>\n",
       "      <td>0.080094</td>\n",
       "      <td>0.041598</td>\n",
       "      <td>0.089356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038497</td>\n",
       "      <td>0.080094</td>\n",
       "      <td>0.041598</td>\n",
       "      <td>0.089356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038498</td>\n",
       "      <td>0.080104</td>\n",
       "      <td>0.041606</td>\n",
       "      <td>0.089357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.041985</td>\n",
       "      <td>0.080497</td>\n",
       "      <td>0.038511</td>\n",
       "      <td>0.089363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0.041985</td>\n",
       "      <td>0.080497</td>\n",
       "      <td>0.038511</td>\n",
       "      <td>0.089363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>0.041985</td>\n",
       "      <td>0.080497</td>\n",
       "      <td>0.038511</td>\n",
       "      <td>0.089363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0.041985</td>\n",
       "      <td>0.080497</td>\n",
       "      <td>0.038511</td>\n",
       "      <td>0.089363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.041985</td>\n",
       "      <td>0.080497</td>\n",
       "      <td>0.038511</td>\n",
       "      <td>0.089363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.042023</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.038485</td>\n",
       "      <td>0.089369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0.042023</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.038485</td>\n",
       "      <td>0.089369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>0.042023</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.038485</td>\n",
       "      <td>0.089369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0.042023</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.038485</td>\n",
       "      <td>0.089369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.042023</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.038485</td>\n",
       "      <td>0.089369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038449</td>\n",
       "      <td>0.080156</td>\n",
       "      <td>0.041707</td>\n",
       "      <td>0.089380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038449</td>\n",
       "      <td>0.080156</td>\n",
       "      <td>0.041707</td>\n",
       "      <td>0.089380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038449</td>\n",
       "      <td>0.080156</td>\n",
       "      <td>0.041707</td>\n",
       "      <td>0.089380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038449</td>\n",
       "      <td>0.080156</td>\n",
       "      <td>0.041707</td>\n",
       "      <td>0.089380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038450</td>\n",
       "      <td>0.080164</td>\n",
       "      <td>0.041714</td>\n",
       "      <td>0.089381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.042031</td>\n",
       "      <td>0.080457</td>\n",
       "      <td>0.038426</td>\n",
       "      <td>0.089391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0.042031</td>\n",
       "      <td>0.080459</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.089391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>0.042031</td>\n",
       "      <td>0.080459</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.089391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0.042031</td>\n",
       "      <td>0.080459</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.089391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.042031</td>\n",
       "      <td>0.080459</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.089391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.080171</td>\n",
       "      <td>0.041698</td>\n",
       "      <td>0.089398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.080171</td>\n",
       "      <td>0.041698</td>\n",
       "      <td>0.089398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.080171</td>\n",
       "      <td>0.041698</td>\n",
       "      <td>0.089398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>0.080171</td>\n",
       "      <td>0.041698</td>\n",
       "      <td>0.089398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>0.080178</td>\n",
       "      <td>0.041704</td>\n",
       "      <td>0.089398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045452</td>\n",
       "      <td>0.080785</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.089490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045452</td>\n",
       "      <td>0.080785</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.089490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045452</td>\n",
       "      <td>0.080785</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.089490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045452</td>\n",
       "      <td>0.080785</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.089490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045452</td>\n",
       "      <td>0.080785</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.089490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045478</td>\n",
       "      <td>0.080811</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.089508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045478</td>\n",
       "      <td>0.080811</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.089508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045478</td>\n",
       "      <td>0.080811</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.089508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045478</td>\n",
       "      <td>0.080811</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.089508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045478</td>\n",
       "      <td>0.080811</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.089508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045513</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.089517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045513</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.089517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045513</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.089517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045513</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.089517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045513</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.089517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>0.080791</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>0.089563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>0.080791</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>0.089563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>0.080791</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>0.089563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>0.080791</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>0.089563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>0.080791</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>0.089563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model seed n_estimators max_depth min_samples_split  TrainError  ValError  \\\n",
       "31    RF    1          850        30                 6    0.041993  0.080487   \n",
       "34    RF    1          850        35                 6    0.041993  0.080487   \n",
       "37    RF    1          850        40                 6    0.041993  0.080487   \n",
       "40    RF    1          850        45                 6    0.041993  0.080487   \n",
       "43    RF    1          850        50                 6    0.041993  0.080487   \n",
       "33    RF    1          850        35                 4    0.038443  0.080184   \n",
       "36    RF    1          850        40                 4    0.038443  0.080184   \n",
       "39    RF    1          850        45                 4    0.038443  0.080184   \n",
       "42    RF    1          850        50                 4    0.038443  0.080184   \n",
       "30    RF    1          850        30                 4    0.038444  0.080191   \n",
       "3     RF    1          650        35                 4    0.038497  0.080094   \n",
       "6     RF    1          650        40                 4    0.038497  0.080094   \n",
       "9     RF    1          650        45                 4    0.038497  0.080094   \n",
       "12    RF    1          650        50                 4    0.038497  0.080094   \n",
       "0     RF    1          650        30                 4    0.038498  0.080104   \n",
       "16    RF    1          750        30                 6    0.041985  0.080497   \n",
       "19    RF    1          750        35                 6    0.041985  0.080497   \n",
       "22    RF    1          750        40                 6    0.041985  0.080497   \n",
       "25    RF    1          750        45                 6    0.041985  0.080497   \n",
       "28    RF    1          750        50                 6    0.041985  0.080497   \n",
       "1     RF    1          650        30                 6    0.042023  0.080508   \n",
       "4     RF    1          650        35                 6    0.042023  0.080508   \n",
       "7     RF    1          650        40                 6    0.042023  0.080508   \n",
       "10    RF    1          650        45                 6    0.042023  0.080508   \n",
       "13    RF    1          650        50                 6    0.042023  0.080508   \n",
       "18    RF    1          750        35                 4    0.038449  0.080156   \n",
       "21    RF    1          750        40                 4    0.038449  0.080156   \n",
       "24    RF    1          750        45                 4    0.038449  0.080156   \n",
       "27    RF    1          750        50                 4    0.038449  0.080156   \n",
       "15    RF    1          750        30                 4    0.038450  0.080164   \n",
       "46    RF    1         1000        30                 6    0.042031  0.080457   \n",
       "49    RF    1         1000        35                 6    0.042031  0.080459   \n",
       "52    RF    1         1000        40                 6    0.042031  0.080459   \n",
       "55    RF    1         1000        45                 6    0.042031  0.080459   \n",
       "58    RF    1         1000        50                 6    0.042031  0.080459   \n",
       "48    RF    1         1000        35                 4    0.038473  0.080171   \n",
       "51    RF    1         1000        40                 4    0.038473  0.080171   \n",
       "54    RF    1         1000        45                 4    0.038473  0.080171   \n",
       "57    RF    1         1000        50                 4    0.038473  0.080171   \n",
       "45    RF    1         1000        30                 4    0.038474  0.080178   \n",
       "32    RF    1          850        30                 8    0.045452  0.080785   \n",
       "35    RF    1          850        35                 8    0.045452  0.080785   \n",
       "38    RF    1          850        40                 8    0.045452  0.080785   \n",
       "41    RF    1          850        45                 8    0.045452  0.080785   \n",
       "44    RF    1          850        50                 8    0.045452  0.080785   \n",
       "17    RF    1          750        30                 8    0.045478  0.080811   \n",
       "20    RF    1          750        35                 8    0.045478  0.080811   \n",
       "23    RF    1          750        40                 8    0.045478  0.080811   \n",
       "26    RF    1          750        45                 8    0.045478  0.080811   \n",
       "29    RF    1          750        50                 8    0.045478  0.080811   \n",
       "2     RF    1          650        30                 8    0.045513  0.080890   \n",
       "5     RF    1          650        35                 8    0.045513  0.080890   \n",
       "8     RF    1          650        40                 8    0.045513  0.080890   \n",
       "11    RF    1          650        45                 8    0.045513  0.080890   \n",
       "14    RF    1          650        50                 8    0.045513  0.080890   \n",
       "47    RF    1         1000        30                 8    0.045475  0.080791   \n",
       "50    RF    1         1000        35                 8    0.045475  0.080791   \n",
       "53    RF    1         1000        40                 8    0.045475  0.080791   \n",
       "56    RF    1         1000        45                 8    0.045475  0.080791   \n",
       "59    RF    1         1000        50                 8    0.045475  0.080791   \n",
       "\n",
       "    deltaErrors  crossVal  \n",
       "31     0.038494  0.089325  \n",
       "34     0.038494  0.089325  \n",
       "37     0.038494  0.089325  \n",
       "40     0.038494  0.089325  \n",
       "43     0.038494  0.089325  \n",
       "33     0.041741  0.089339  \n",
       "36     0.041741  0.089339  \n",
       "39     0.041741  0.089339  \n",
       "42     0.041741  0.089339  \n",
       "30     0.041747  0.089339  \n",
       "3      0.041598  0.089356  \n",
       "6      0.041598  0.089356  \n",
       "9      0.041598  0.089356  \n",
       "12     0.041598  0.089356  \n",
       "0      0.041606  0.089357  \n",
       "16     0.038511  0.089363  \n",
       "19     0.038511  0.089363  \n",
       "22     0.038511  0.089363  \n",
       "25     0.038511  0.089363  \n",
       "28     0.038511  0.089363  \n",
       "1      0.038485  0.089369  \n",
       "4      0.038485  0.089369  \n",
       "7      0.038485  0.089369  \n",
       "10     0.038485  0.089369  \n",
       "13     0.038485  0.089369  \n",
       "18     0.041707  0.089380  \n",
       "21     0.041707  0.089380  \n",
       "24     0.041707  0.089380  \n",
       "27     0.041707  0.089380  \n",
       "15     0.041714  0.089381  \n",
       "46     0.038426  0.089391  \n",
       "49     0.038428  0.089391  \n",
       "52     0.038428  0.089391  \n",
       "55     0.038428  0.089391  \n",
       "58     0.038428  0.089391  \n",
       "48     0.041698  0.089398  \n",
       "51     0.041698  0.089398  \n",
       "54     0.041698  0.089398  \n",
       "57     0.041698  0.089398  \n",
       "45     0.041704  0.089398  \n",
       "32     0.035333  0.089490  \n",
       "35     0.035333  0.089490  \n",
       "38     0.035333  0.089490  \n",
       "41     0.035333  0.089490  \n",
       "44     0.035333  0.089490  \n",
       "17     0.035333  0.089508  \n",
       "20     0.035333  0.089508  \n",
       "23     0.035333  0.089508  \n",
       "26     0.035333  0.089508  \n",
       "29     0.035333  0.089508  \n",
       "2      0.035377  0.089517  \n",
       "5      0.035377  0.089517  \n",
       "8      0.035377  0.089517  \n",
       "11     0.035377  0.089517  \n",
       "14     0.035377  0.089517  \n",
       "47     0.035317  0.089563  \n",
       "50     0.035317  0.089563  \n",
       "53     0.035317  0.089563  \n",
       "56     0.035317  0.089563  \n",
       "59     0.035317  0.089563  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by=[\"crossVal\",\"ValError\", \"deltaErrors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31\tRF\t1\t850\t30\t6\t0.041993\t0.080487\t0.038494\t0.089325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestRfGap = RandomForestRegressor(criterion='mse', n_estimators=850, max_depth=30, min_samples_split=6, random_state=1).fit(X_train_gap, y_train_gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neutral Net (Multi-Layer Perceptron regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formation energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### ANN ##############################\n",
    "hidden_layer_sizes = [(100,),(50,50), (50,100,50)]\n",
    "activations = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "solvers=['lbfgs','adam']\n",
    "learning_rates = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "seeds = [1]\n",
    "results_df = pd.DataFrame(columns=['activation',\"hidden_layer_size\",\"solver\",\"learning_rate\",'TrainError', 'ValError', 'deltaErrors'])\n",
    "\n",
    "for activation in activations:\n",
    "    for solver in solvers:\n",
    "        for learning_rate in learning_rates:\n",
    "            for hidden_layer_size in hidden_layer_sizes:\n",
    "                mlp = MLPRegressor(activation=activation, solver=solver, learning_rate=learning_rate, hidden_layer_sizes=hidden_layer_size).fit(X_train_energ, y_train_energ)\n",
    "                trainError = rmsle(y_train_energ, abs(mlp.predict(X_train_energ)))\n",
    "                valError = rmsle(y_val_energ, abs(mlp.predict(X_val_energ)))\n",
    "                cross_Val = evaluate_CV(mlp, X_fullMinMax, y_fe)\n",
    "                results_df = results_df.append({'activation':activation,\"hidden_layer_size\":hidden_layer_size,\"solver\":solver,\"learning_rate\":learning_rate,\"TrainError\":trainError, 'ValError':valError, 'deltaErrors':abs(trainError-valError),'crossVal':cross_Val}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>hidden_layer_size</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>TrainError</th>\n",
       "      <th>ValError</th>\n",
       "      <th>deltaErrors</th>\n",
       "      <th>crossVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>relu</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>0.030703</td>\n",
       "      <td>0.030816</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.031325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>relu</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.026771</td>\n",
       "      <td>0.030554</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.031591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>relu</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>0.030064</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.031689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(50, 100, 50)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>0.030880</td>\n",
       "      <td>0.030808</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.031788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>relu</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>0.027824</td>\n",
       "      <td>0.030575</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.031805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(50, 100, 50)</td>\n",
       "      <td>adam</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>0.052076</td>\n",
       "      <td>0.051262</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.065256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(50, 100, 50)</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.053991</td>\n",
       "      <td>0.052534</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.066034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(50, 100, 50)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>0.086962</td>\n",
       "      <td>0.085022</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.086544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(50, 100, 50)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>0.086831</td>\n",
       "      <td>0.084814</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.086601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(50, 100, 50)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.086695</td>\n",
       "      <td>0.084689</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.086615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation hidden_layer_size solver learning_rate  TrainError  ValError  \\\n",
       "58       relu          (50, 50)  lbfgs    invscaling    0.030703  0.030816   \n",
       "54       relu            (100,)  lbfgs      constant    0.026771  0.030554   \n",
       "60       relu            (100,)  lbfgs      adaptive    0.027959  0.030064   \n",
       "41       tanh     (50, 100, 50)  lbfgs    invscaling    0.030880  0.030808   \n",
       "57       relu            (100,)  lbfgs    invscaling    0.027824  0.030575   \n",
       "..        ...               ...    ...           ...         ...       ...   \n",
       "35   logistic     (50, 100, 50)   adam      adaptive    0.052076  0.051262   \n",
       "29   logistic     (50, 100, 50)   adam      constant    0.053991  0.052534   \n",
       "23   logistic     (50, 100, 50)  lbfgs    invscaling    0.086962  0.085022   \n",
       "26   logistic     (50, 100, 50)  lbfgs      adaptive    0.086831  0.084814   \n",
       "20   logistic     (50, 100, 50)  lbfgs      constant    0.086695  0.084689   \n",
       "\n",
       "    deltaErrors  crossVal  \n",
       "58     0.000114  0.031325  \n",
       "54     0.003783  0.031591  \n",
       "60     0.002105  0.031689  \n",
       "41     0.000072  0.031788  \n",
       "57     0.002751  0.031805  \n",
       "..          ...       ...  \n",
       "35     0.000814  0.065256  \n",
       "29     0.001457  0.066034  \n",
       "23     0.001940  0.086544  \n",
       "26     0.002017  0.086601  \n",
       "20     0.002006  0.086615  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by=[\"crossVal\",\"ValError\", \"deltaErrors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58\trelu\t(50, 50)\tlbfgs\tinvscaling\t0.030703\t0.030816\t0.000114\t0.031325"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Band gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "############### ANN ##############################\n",
    "hidden_layer_sizes = [(100,),(50,50), (50,100,50),(50,100,100,50)]\n",
    "activations = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "solvers=['lbfgs','adam']\n",
    "learning_rates = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "seeds = [1]\n",
    "results_df = pd.DataFrame(columns=['activation',\"hidden_layer_size\",\"solver\",\"learning_rate\",'TrainError', 'ValError', 'deltaErrors'])\n",
    "\n",
    "for activation in activations:\n",
    "    for solver in solvers:\n",
    "        for learning_rate in learning_rates:\n",
    "            for hidden_layer_size in hidden_layer_sizes:\n",
    "                mlp = MLPRegressor(activation=activation, solver=solver, learning_rate=learning_rate, hidden_layer_sizes=hidden_layer_size).fit(X_train_gap, y_train_gap)\n",
    "                trainError = rmsle(y_train_gap, abs(mlp.predict(X_train_gap)))\n",
    "                valError = rmsle(y_val_gap, abs(mlp.predict(X_val_gap)))\n",
    "                cross_Val = evaluate_CV(mlp, X_fullMinMax, y_be)\n",
    "                results_df = results_df.append({'activation':activation,\"hidden_layer_size\":hidden_layer_size,\"solver\":solver,\"learning_rate\":learning_rate,\"TrainError\":trainError, 'ValError':valError, 'deltaErrors':abs(trainError-valError),'crossVal':cross_Val}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>hidden_layer_size</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>TrainError</th>\n",
       "      <th>ValError</th>\n",
       "      <th>deltaErrors</th>\n",
       "      <th>crossVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(50, 100, 50)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>0.076627</td>\n",
       "      <td>0.073540</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.082592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>0.076890</td>\n",
       "      <td>0.075026</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.082881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(50, 100, 50)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.078058</td>\n",
       "      <td>0.071912</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.082995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(50, 100, 50)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>0.077632</td>\n",
       "      <td>0.072404</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.083001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>0.077870</td>\n",
       "      <td>0.073002</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.083208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>identity</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.113267</td>\n",
       "      <td>0.091627</td>\n",
       "      <td>0.021640</td>\n",
       "      <td>0.113185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>identity</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.110986</td>\n",
       "      <td>0.090602</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.113203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>identity</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>adam</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>0.114022</td>\n",
       "      <td>0.093414</td>\n",
       "      <td>0.020608</td>\n",
       "      <td>0.113265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>identity</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>adam</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>0.113628</td>\n",
       "      <td>0.092374</td>\n",
       "      <td>0.021254</td>\n",
       "      <td>0.114066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>identity</td>\n",
       "      <td>(50, 100, 50)</td>\n",
       "      <td>adam</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>0.112729</td>\n",
       "      <td>0.089031</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.114144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation hidden_layer_size solver learning_rate  TrainError  ValError  \\\n",
       "41       tanh     (50, 100, 50)  lbfgs    invscaling    0.076627  0.073540   \n",
       "43       tanh          (50, 50)  lbfgs      adaptive    0.076890  0.075026   \n",
       "38       tanh     (50, 100, 50)  lbfgs      constant    0.078058  0.071912   \n",
       "44       tanh     (50, 100, 50)  lbfgs      adaptive    0.077632  0.072404   \n",
       "40       tanh          (50, 50)  lbfgs    invscaling    0.077870  0.073002   \n",
       "..        ...               ...    ...           ...         ...       ...   \n",
       "9    identity            (100,)   adam      constant    0.113267  0.091627   \n",
       "10   identity          (50, 50)   adam      constant    0.110986  0.090602   \n",
       "13   identity          (50, 50)   adam    invscaling    0.114022  0.093414   \n",
       "12   identity            (100,)   adam    invscaling    0.113628  0.092374   \n",
       "14   identity     (50, 100, 50)   adam    invscaling    0.112729  0.089031   \n",
       "\n",
       "    deltaErrors  crossVal  \n",
       "41     0.003087  0.082592  \n",
       "43     0.001864  0.082881  \n",
       "38     0.006146  0.082995  \n",
       "44     0.005228  0.083001  \n",
       "40     0.004868  0.083208  \n",
       "..          ...       ...  \n",
       "9      0.021640  0.113185  \n",
       "10     0.020384  0.113203  \n",
       "13     0.020608  0.113265  \n",
       "12     0.021254  0.114066  \n",
       "14     0.023697  0.114144  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by=[\"crossVal\",\"ValError\", \"deltaErrors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41\ttanh\t(50, 100, 50)\tlbfgs\tinvscaling\t0.076627\t0.073540\t0.003087\t0.082592"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best trained models we form a weighted average ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formation Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFe = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03279555483040591\n"
     ]
    }
   ],
   "source": [
    "bestKnnFe = KNeighborsRegressor(n_neighbors=5, weights='uniform', metric='manhattan').fit(X_train_energ, y_train_energ)\n",
    "cross_KNN_Fe = evaluate_CV(bestKnnFe, X_fullMinMax, y_fe)\n",
    "valErrorKNN = rmsle(y_val_energ, (bestKnnFe.predict(X_val_energ)))\n",
    "resultKNNFe = bestKnnFe.predict(X_full_Test_MinMax)\n",
    "resultsFe[\"KNN\"] = resultKNNFe\n",
    "print(valErrorKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leaving this model out as this is noticeably worse model\n",
    "#bestSvmFe = SVR(kernel=\"rbf\", gamma=\"scale\").fit(X_train_energ, y_train_energ)\n",
    "#cross_SVM_Fe = evaluate_CV(bestSvmFe, X_fullMinMax, y_fe)\n",
    "#valErrorSVM = rmsle(y_val_energ, (bestSvmFe.predict(X_val_energ)))\n",
    "#resultSVMFe = bestSvmFe.predict(X_val_energ)\n",
    "#resultsFe[\"SVM\"] = resultSVMFe\n",
    "#print(valErrorSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030167500161596885\n"
     ]
    }
   ],
   "source": [
    "bestRfFe = RandomForestRegressor(criterion='mse', n_estimators=1000, max_depth=35, min_samples_split=4, random_state=1).fit(X_train_energ, y_train_energ)\n",
    "cross_RF_Fe = evaluate_CV(bestRfFe, X_fullMinMax, y_fe)\n",
    "valErrorRF = rmsle(y_val_energ, (bestRfFe.predict(X_val_energ)))\n",
    "resultRFFe = bestRfFe.predict(X_full_Test_MinMax)\n",
    "resultsFe[\"RF\"] = resultRFFe\n",
    "print(valErrorRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03154900116513413\n"
     ]
    }
   ],
   "source": [
    "bestMlpFe = MLPRegressor(activation=\"relu\", solver=\"lbfgs\", learning_rate=\"invscaling\", hidden_layer_sizes=(50, 50)).fit(X_train_energ, y_train_energ)\n",
    "cross_Mlp_Fe = evaluate_CV(bestMlpFe, X_fullMinMax, y_fe)\n",
    "valErrorMLP = rmsle(y_val_energ, (bestMlpFe.predict(X_val_energ)))\n",
    "resultMlpFe = bestMlpFe.predict(X_full_Test_MinMax)\n",
    "resultsFe[\"MLP\"] = resultMlpFe\n",
    "print(valErrorMLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Cross-Ref error as weighting factor and evaluate Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryError = cross_KNN_Fe+cross_RF_Fe+cross_Mlp_Fe\n",
    "resultsFe[\"Weighted\"] = cross_KNN_Fe/summaryError*resultsFe[\"KNN\"] + cross_RF_Fe/summaryError*resultsFe[\"RF\"] + cross_Mlp_Fe/summaryError*resultsFe[\"MLP\"]\n",
    "\n",
    "#errorWeighted = rmsle(y_val_energ, resultsFe[\"Weighted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(errorWeighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Band Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsGap = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbestKnnGap = KNeighborsRegressor(n_neighbors=5, weights=\\'distance\\', metric=\\'manhattan\\').fit(X_train_gap, y_train_gap)\\ncross_KNN_Gap = evaluate_CV(bestKnnGap, X_fullMinMax, y_be)\\n\\nvalErrorKNN = rmsle(y_val_gap, (bestKnnGap.predict(X_val_gap)))\\nresultKNNGap = bestKnnGap.predict(X_full_Test_MinMax)\\nresultsGap[\"KNN\"] = resultKNNGap\\nprint(valErrorKNN)\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "bestKnnGap = KNeighborsRegressor(n_neighbors=5, weights='distance', metric='manhattan').fit(X_train_gap, y_train_gap)\n",
    "cross_KNN_Gap = evaluate_CV(bestKnnGap, X_fullMinMax, y_be)\n",
    "\n",
    "valErrorKNN = rmsle(y_val_gap, (bestKnnGap.predict(X_val_gap)))\n",
    "resultKNNGap = bestKnnGap.predict(X_full_Test_MinMax)\n",
    "resultsGap[\"KNN\"] = resultKNNGap\n",
    "print(valErrorKNN)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0714004739716549\n"
     ]
    }
   ],
   "source": [
    "bestSvmGap = SVR(kernel=\"poly\", gamma=\"scale\").fit(X_train_gap, y_train_gap)\n",
    "cross_SVM_Gap = evaluate_CV(bestSvmGap, X_fullMinMax, y_be)\n",
    "\n",
    "valErrorSVM = rmsle(y_val_gap, (bestSvmGap.predict(X_val_gap)))\n",
    "resultSVMGap = bestSvmGap.predict(X_full_Test_MinMax)\n",
    "resultsGap[\"SVM\"] = resultSVMGap\n",
    "print(valErrorSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbestRfGap = RandomForestRegressor(criterion=\\'mse\\', n_estimators=850, max_depth=30, min_samples_split=6, random_state=1).fit(X_train_gap, y_train_gap)\\ncross_RF_Gap = evaluate_CV(bestRfGap, X_fullMinMax, y_be)\\n\\nvalErrorRF = rmsle(y_val_gap, (bestRfGap.predict(X_val_gap)))\\nresultRFGap = bestRfGap.predict(X_full_Test_MinMax)\\nresultsGap[\"RF\"] = resultRFGap\\nprint(valErrorRF)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "bestRfGap = RandomForestRegressor(criterion='mse', n_estimators=850, max_depth=30, min_samples_split=6, random_state=1).fit(X_train_gap, y_train_gap)\n",
    "cross_RF_Gap = evaluate_CV(bestRfGap, X_fullMinMax, y_be)\n",
    "\n",
    "valErrorRF = rmsle(y_val_gap, (bestRfGap.predict(X_val_gap)))\n",
    "resultRFGap = bestRfGap.predict(X_full_Test_MinMax)\n",
    "resultsGap[\"RF\"] = resultRFGap\n",
    "print(valErrorRF)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_full_Test_MinMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07282709000517473\n"
     ]
    }
   ],
   "source": [
    "bestMlpGap = MLPRegressor(activation=\"tanh\", solver=\"lbfgs\", learning_rate=\"invscaling\", hidden_layer_sizes=(50, 100, 50)).fit(X_train_gap, y_train_gap)\n",
    "cross_Mlp_Gap = evaluate_CV(bestMlpFe, X_fullMinMax, y_be)\n",
    "\n",
    "valErrorMlp = rmsle(y_val_gap, (bestMlpGap.predict(X_val_gap)))\n",
    "resultMlpGap = bestMlpGap.predict(X_full_Test_MinMax)\n",
    "resultsGap[\"MLP\"] = resultMlpGap\n",
    "print(valErrorMlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Cross-Ref error as weighting factor and evaluate Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summaryError = cross_SVM_Gap+cross_RF_Gap+cross_Mlp_Gap\n",
    "#resultsGap[\"Weighted\"] = cross_SVM_Gap/summaryError*resultsGap[\"SVM\"] + cross_RF_Gap/summaryError*resultsGap[\"RF\"] + cross_Mlp_Gap/summaryError*resultsGap[\"MLP\"]\n",
    "\n",
    "summaryError = cross_SVM_Gap+cross_Mlp_Gap\n",
    "resultsGap[\"Weighted\"] = cross_SVM_Gap/summaryError*resultsGap[\"SVM\"] + cross_Mlp_Gap/summaryError*resultsGap[\"MLP\"]\n",
    "\n",
    "\n",
    "#errorWeighted = rmsle(y_val_gap, resultsGap[\"Weighted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#errorWeighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission file\n",
    "def save_results(y_fe_pred, y_be_pred, name):\n",
    "    results = pd.DataFrame({\"id\": test.id, \"formation_energy_ev_natom\": y_fe_pred, \"bandgap_energy_ev\": y_be_pred})\n",
    "    results.to_csv(name + \".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(resultsFe[\"RF\"] ,resultsGap[\"SVM\"], \"output2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
